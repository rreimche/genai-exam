{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtqByxksxE8f6x6A2gZGa+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rreimche/genai-exam/blob/main/SLRev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lOrwSJU5Lyix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites:\n",
        "- Google Colab\n",
        "- Access to a Google Colab Secret named \"HF_API_TOKEN\" containing a Huggingface API token with read access."
      ],
      "metadata": {
        "id": "l1dAEpCOLUHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Settings\n",
        "from google.colab import userdata\n",
        "\n",
        "download_dir = \"papers\"  # directory name to download papers to revie to\n",
        "huggingface_apikey = userdata.get('HF_API_TOKEN')  # use colab secrets to store the huggingface api key\n",
        "groq_key = userdata.get('GROQ_KEY')  #  use colab secrets to store the huggingface api key\n"
      ],
      "metadata": {
        "id": "q-ZPkAZ34Aem",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Declare bibtex references and parse them into a variable for later usage\n",
        "\n",
        "\n",
        "bibtext_references = \"\"\"\n",
        "\n",
        "\n",
        "@misc{qian2024chatdevcommunicativeagentssoftware,\n",
        "      title={ChatDev: Communicative Agents for Software Development},\n",
        "      author={Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},\n",
        "      year={2024},\n",
        "      eprint={2307.07924},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.SE},\n",
        "      url={https://arxiv.org/abs/2307.07924},\n",
        "},\n",
        "\n",
        "@misc{nguyen2024agilecoderdynamiccollaborativeagents,\n",
        "      title={AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology},\n",
        "      author={Minh Huynh Nguyen and Thang Phan Chau and Phong X. Nguyen and Nghi D. Q. Bui},\n",
        "      year={2024},\n",
        "      eprint={2406.11912},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.SE},\n",
        "      url={https://arxiv.org/abs/2406.11912},\n",
        "},\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "9OLg8Lv_RdoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258cb5c7-081b-42cc-9aaf-1eb1c4cebd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entry Type: misc\n",
            "  Key: qian2024chatdevcommunicativeagentssoftware\n",
            "  url: https://arxiv.org/abs/2307.07924\n",
            "  primaryclass: cs.SE\n",
            "  archiveprefix: arXiv\n",
            "  eprint: 2307.07924\n",
            "  year: 2024\n",
            "  author: Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun\n",
            "  title: ChatDev: Communicative Agents for Software Development\n",
            "--------------------\n",
            "Entry Type: misc\n",
            "  Key: nguyen2024agilecoderdynamiccollaborativeagents\n",
            "  url: https://arxiv.org/abs/2406.11912\n",
            "  primaryclass: cs.SE\n",
            "  archiveprefix: arXiv\n",
            "  eprint: 2406.11912\n",
            "  year: 2024\n",
            "  author: Minh Huynh Nguyen and Thang Phan Chau and Phong X. Nguyen and Nghi D. Q. Bui\n",
            "  title: AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "!pip install -q autogen arxiv scholarly crossrefapi beautifulsoup4 requests cloudscraper pymupdf nltk autogen-agentchat autogen-ext[openai] groq pymupdf;\n",
        "!pip install -q --pre bibtexparser;"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ONfbxa-ELoqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a16c534-3927-47a5-d819-a8a7ddb560e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m642.5/642.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for free-proxy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-sdk 1.16.0 requires opentelemetry-api==1.16.0, but you have opentelemetry-api 1.30.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preparation for agents: model client connections\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "from autogen_core.tools import FunctionTool\n",
        "from autogen_core.models import UserMessage\n",
        "#from autogen_agentchat.ui import Console\n",
        "from autogen_core import CancellationToken\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "\n",
        "# INSTANTIATE MODEL CLIENTS\n",
        "\n",
        "# This client will be used for paper summarization\n",
        "text_model_client = OpenAIChatCompletionClient(\n",
        "    #model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    base_url=\"https://router.huggingface.co/hf-inference/v1\",\n",
        "    api_key=huggingface_apikey,\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": False,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# We need another inference point for downloader agent,\n",
        "# because huggingface can't serve reflection on tool use\n",
        "# so that autogen agent understands it\n",
        "tool_model_client = OpenAIChatCompletionClient(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=groq_key,\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# CHECK CONNECTION\n",
        "\n",
        "async def check_model_connect() -> None:\n",
        "    messages = [\n",
        "        UserMessage(content=\"What is the capital of France?\", source=\"user\"),\n",
        "    ]\n",
        "    response = await text_model_client.create(messages=messages)\n",
        "    response_downloader = await tool_model_client.create(messages=messages)\n",
        "\n",
        "    print(response.content)\n",
        "    print(response_downloader.content)\n",
        "\n",
        "#await check_model_connect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwt9LJMLbU6m",
        "outputId": "018f5160-3003-4da7-e777-86c43adb5975",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris. It's a city known worldwide for its beautiful architecture, museums, fashion, and cuisine. However, Paris is not a country, it's a city, and France is the country.\n",
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloader agent\n",
        "import arxiv\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from autogen_core.models import ChatCompletionClient\n",
        "from autogen_core import message_handler\n",
        "\n",
        "# HELPER AND TOOL FUNCTIONS\n",
        "\n",
        "def maybe_create_dir(donwload_dir: str) -> None:\n",
        "    \"\"\"\n",
        "        A helper function to create the downloads directory\n",
        "        in colab root if the directory is not yet present.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        os.makedirs(donwload_dir, exist_ok=True)\n",
        "        #print(f\"Directory '{download_dir}' created successfully.\")\n",
        "    except OSError as e:\n",
        "        raise Exception(f\"Error creating directory '{download_dir}': {e}\")\n",
        "\n",
        "def download_paper(eprint_id: str) -> str:\n",
        "    \"\"\"\n",
        "        Receives a eprint_id of a paper from arxiv, downloads the specified paper\n",
        "        and saves it in downloads directory.\n",
        "        The filepath of the downloaded paper is in the resulting dictionary\n",
        "        with the key \"filepath\".\n",
        "\n",
        "        :param eprint_id: string, the arxiv eprint_id.\n",
        "        :return: string with filepath of the downloaded paper.\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(eprint_id) > 0, \"eprint_id cannot be empty\"\n",
        "\n",
        "    result = {\n",
        "        \"eprint_id\": eprint_id,\n",
        "        \"success\": False,\n",
        "        \"filepath\": None,\n",
        "        }\n",
        "\n",
        "\n",
        "    if eprint_id:\n",
        "        #print(f\"{datetime.datetime.now()} - Trying arXiv for: {eprint_id}\")\n",
        "        try:\n",
        "            client = arxiv.Client()\n",
        "            search = arxiv.Search(id_list=[eprint_id], max_results=1)\n",
        "\n",
        "            #arxiv_result = next(search.results(), None)\n",
        "            arxiv_result = next(client.results(search))\n",
        "            if arxiv_result:\n",
        "                #print(f\"  Found on arXiv: {arxiv_result.title}\")\n",
        "                maybe_create_dir(download_dir)\n",
        "                filepath = os.path.join(download_dir, f\"{arxiv_result.title.replace(' ', '_')}.pdf\")\n",
        "                arxiv_result.download_pdf(filename=filepath)\n",
        "                result[\"success\"] = True\n",
        "                result[\"filepath\"] = filepath\n",
        "                #print(f\"  Download successful: {filepath}\")\n",
        "            else:\n",
        "                # print(f\"  No arXiv result found for ID {eprint_id}.\")\n",
        "                raise Exception(f\"ERROR: No arXiv result found for ID {eprint_id}.\")\n",
        "                #return f\"ERROR: No arXiv result found for ID {eprint_id}.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            #print(f\"arXiv download failed for: {eprint_id}: {e}\")\n",
        "            raise Exception(f\"ERROR: arXiv download failed for: {eprint_id}: {e}\")\n",
        "            #return f\"ERROR: arXiv download failed for: {eprint_id}: {e}\"\n",
        "\n",
        "    # Check if the download was NOT successful\n",
        "    if not result[\"success\"]:\n",
        "        #print(f\"{datetime.datetime.now()} - Download failed or not attempted for: {eprint_id}\")\n",
        "        raise Exception(f\"ERROR: Download failed or not attempted for: {eprint_id}\")\n",
        "        #return f\"ERROR: Download failed or not attempted for: {eprint_id}\"\n",
        "\n",
        "    return result[\"filepath\"]\n",
        "\n",
        "\n",
        "# DOWNLOADER AGENT WITH TOOL\n",
        "\n",
        "def create_downloader(given_name: str) -> AssistantAgent:\n",
        "    downloader_tool = FunctionTool(download_paper, description=\"Given a string denoting an eprint_id of a page on arxiv, downloads a paper\")\n",
        "\n",
        "    return AssistantAgent(\n",
        "        name=given_name,\n",
        "        description=\"An agent that uses downloader tool to download a paper from Arxiv identified by a eprint_id\",\n",
        "        model_client=tool_model_client,\n",
        "        tools=[downloader_tool],\n",
        "        reflect_on_tool_use=True,\n",
        "        system_message=\"\"\"\n",
        "            Use downloader tool to download specified paper(s) from arxiv.\n",
        "            Here is an example of how you must respond in success case:\n",
        "              'mypapers/veryinterstingpaper.pdf'\n",
        "\n",
        "            Very important: You MUST return the full filepath of the downloaded\n",
        "            paper EXACTLY as it was given by the downloader tool.\n",
        "\n",
        "            If download was not successful, respond like this:\n",
        "              'ERROR: Download for paper with eprint id XXX failed for the following reason: REASON'.\n",
        "          \"\"\",\n",
        "    )\n",
        "\n",
        "def create_downloader_nameless() -> AssistantAgent:\n",
        "    downloader_tool = FunctionTool(download_paper, description=\"Given a string denoting an eprint_id of a page on arxiv, downloads a paper\")\n",
        "\n",
        "    return AssistantAgent(\n",
        "        description=\"An agent that uses downloader tool to download a paper from Arxiv identified by a eprint_id\",\n",
        "        model_client=tool_model_client,\n",
        "        tools=[downloader_tool],\n",
        "        reflect_on_tool_use=True,\n",
        "        system_message=\"\"\"\n",
        "            Use downloader tool to download specified paper(s) from arxiv.\n",
        "            Here is an example of how you must respond in success case:\n",
        "              'mypapers/veryinterstingpaper.pdf'\n",
        "\n",
        "            Very important: You MUST return the full filepath of the downloaded\n",
        "            paper EXACTLY as it was given by the downloader tool.\n",
        "\n",
        "            If download was not successful, respond like this:\n",
        "              'ERROR: Download for paper with eprint id XXX failed for the following reason: REASON'.\n",
        "          \"\"\",\n",
        "    )\n",
        "\n",
        "# THE SAME BUT USING CORE LIBRARY\n",
        "\n",
        "@dataclass\n",
        "class DownloadTask:\n",
        "    # Task for downloader agent\n",
        "    task: str\n",
        "\n",
        "@dataclass\n",
        "class DownloadTaskResult:\n",
        "    result: str\n",
        "\n",
        "async def async_download_paper(eprint_id: str) -> str:\n",
        "    \"\"\"\n",
        "        Receives a eprint_id of a paper from arxiv, downloads the specified paper\n",
        "        and saves it in downloads directory.\n",
        "        The filepath of the downloaded paper is in the resulting dictionary\n",
        "        with the key \"filepath\".\n",
        "\n",
        "        :param eprint_id: string, the arxiv eprint_id.\n",
        "        :return: string with filepath of the downloaded paper.\n",
        "    \"\"\"\n",
        "    return download_paper(eprint_id)\n",
        "\n",
        "async_downloader_tool = FunctionTool(\n",
        "    async_download_paper,\n",
        "    description=\"Given a string denoting an eprint_id of a page on arxiv, downloads a paper\"\n",
        ")\n",
        "\n",
        "# TODO Maybe finish\n",
        "class DownloaderAgent(RoutedAgent):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_client: ChatCompletionClient,\n",
        "    ) -> None:\n",
        "        super().__init__(description=\"Downloader Agent\")\n",
        "        self._model_client = model_client\n",
        "\n",
        "    @message_handler\n",
        "    async def handle_task(self, message: DownloadTask, ctx: MessageContext) -> DownloadTaskResult:\n",
        "        # Run the chat completion with the stock_price_tool defined above.\n",
        "        cancellation_token = CancellationToken()\n",
        "        #create_result = await self._model_client.create(\n",
        "        #    messages=[UserMessage(message.task], tools=[async_downloader_tool], cancellation_token=cancellation_token\n",
        "        #)\n",
        "        #create_result.content\n",
        "        #return DownloadTaskResult(result=model_result.content)\n",
        "\n",
        "\n",
        "# CHECK IF DOWNLOAD WORKS\n",
        "\n",
        "async def downloader_run() -> None:\n",
        "    response = await create_downloader(\"Test\").on_messages(\n",
        "        [TextMessage(content=\"Download the paper with eprint_id 2402.01411\", source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message)\n",
        "    print(response.chat_message.content)\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "#await downloader_run()\n",
        "\n",
        "async def custom_downloader_run() -> None:\n",
        "    runtime = SingleThreadedAgentRuntime()\n",
        "    await DownloaderAgent.register(\n",
        "        runtime, \"downloader\", lambda: DownloaderAgent(model_client=text_model_client)\n",
        "    )"
      ],
      "metadata": {
        "id": "I5Zv1Bs32eOb"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parser agent\n",
        "import pymupdf\n",
        "#import nltk\n",
        "#from nltk.tokenize import word_tokenize\n",
        "\n",
        "#nltk.download('punkt_tab')\n",
        "\n",
        "def parse_pdf(filepath: str) -> str:\n",
        "    try:\n",
        "        with pymupdf.open(filepath) as doc:\n",
        "            text = \"\"\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "            # print(f\"Successfully parsed: {title} (arXiv ID: {eprint_id})\")\n",
        "            return text\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Error parsing {title} ({filepath}): {e}\")\n",
        "        raise Exception(f\"ERROR: Error parsing {filepath}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_parser(name: str) -> AssistantAgent:\n",
        "    parser_tool = FunctionTool(\n",
        "        parse_pdf,\n",
        "        description=\"A tool that takes a filepath of a pdf file, parses the file and returns the text\"\n",
        "    )\n",
        "\n",
        "    return AssistantAgent(\n",
        "        name=\"parser\",\n",
        "        model_client=tool_model_client,\n",
        "        system_message=\"\"\"\n",
        "            For a given filepath of a scientific paper,\n",
        "            you use the provided tool, which parses the paper and returns text.\n",
        "            Then you return the text in your response.\n",
        "          \"\"\",\n",
        "        tools=[parser_tool]\n",
        "    )\n",
        "\n",
        "# CHECK IF PARSING WORKS\n",
        "\n",
        "async def parser_run() -> None:\n",
        "    response = await create_parser(\"test_parser\").on_messages(\n",
        "        [TextMessage(content=\"Parse this paper: papers/CodePori:_Large-Scale_System_for_Autonomous_Software_Development_Using_Multi-Agent_Technology.pdf\", source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message)\n",
        "    text = response.chat_message.content\n",
        "    #print(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "#test_paper_text = await parser_run()  # we'll need the variable to test other agents\n",
        "#print(test_paper_text)"
      ],
      "metadata": {
        "id": "W39p-AOvGq21",
        "collapsed": true
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Conceptualizer\n",
        "\n",
        "\n",
        "def create_conceptualizer(name: str) -> AssistantAgent:\n",
        "    return AssistantAgent(\n",
        "        name=name,\n",
        "        model_client=text_model_client,\n",
        "        system_message=\"\"\"\n",
        "          You are a professor of computer science specialized in multi agent systems\n",
        "          and generative AI. Given a text of a scientific paper, write a conceptualization\n",
        "          of it -- provide structure of the paper and key contributions delivered.\n",
        "          Write structured, using headers and bullet points. Provide short descriptions\n",
        "          of key contributions. Fit your answer in 500 words.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "# CHECK IF CONCEPTUALIZATION WORKS\n",
        "\n",
        "async def concept_run(paper_text: str) -> None:\n",
        "    response = await create_conceptualizer(\"Test conceptualizer\").on_messages(\n",
        "        [TextMessage(content=paper_text, source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    #print(paper_text)\n",
        "    #print(response.inner_messages)\n",
        "    print(response.chat_message.models_usage)\n",
        "    #print(response.chat_message.content)\n",
        "    return response.chat_message.content\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "#conceptualization = await concept_run(test_paper_text)  # we'll need the variable later for testing of other agents\n",
        "#print(conceptualization)\n"
      ],
      "metadata": {
        "id": "UnE-WYLx1RAz",
        "collapsed": true
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Summarizer agent\n",
        "\n",
        "sysprompt1 = \"\"\"\n",
        "        You are a professor of computer science\n",
        "        and also qualified and experienced reviewer and critic of scientific papers.\n",
        "        You will be given a paper text and it's conceptualisation.\n",
        "        Summarize the paper using the points provided in conceptualisation.\n",
        "        You must fit your summarization in 500 words.\n",
        "        It is very important to depict the key contributions of the paper.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "sysprompt2 = \"\"\"\n",
        "        You are a professor of computer science\n",
        "        and also qualified and experienced reviewer and critic of scientific papers.\n",
        "        You will be given a conceptualisation of a paper.\n",
        "        Write a summarization based on conceptualization.\n",
        "        You must fit your summarization in 500 words.\n",
        "        It is very important to depict the key contributions of the paper.\n",
        "\"\"\"\n",
        "\n",
        "summarizer_agent = AssistantAgent(\n",
        "    name=\"summarizer\",\n",
        "    model_client=text_model_client,\n",
        "    system_message=sysprompt1\n",
        ")\n",
        "\n",
        "# CHECK IF SUMMARIZING WORKS\n",
        "\n",
        "async def summarizer_run(paper_text: str, conceptualization: str) -> None:\n",
        "\n",
        "    prompt1 = f\"\"\"\n",
        "      ------start paper text-------\n",
        "      {paper_text}\n",
        "      ------end paper text-------\n",
        "      ------start conceptualization-------\n",
        "      {conceptualization}\n",
        "      ------end conceptualization-------\n",
        "      \"\"\"\n",
        "\n",
        "    prompt2 = f\"\"\"\n",
        "      ------start conceptualization-------\n",
        "      {conceptualization}\n",
        "      ------end conceptualization-------\n",
        "      \"\"\"\n",
        "\n",
        "    prompt3 = f\"\"\"\n",
        "      ------start paper text-------\n",
        "      {paper_text}\n",
        "      ------end paper text-------\n",
        "      \"\"\"\n",
        "\n",
        "    prompt = prompt2\n",
        "\n",
        "\n",
        "    response = await summarizer_agent.on_messages(\n",
        "        [TextMessage(content=prompt, source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    #print(paper_text)\n",
        "    #print(response.inner_messages)\n",
        "    print(response.chat_message.models_usage)\n",
        "    return response.chat_message.content\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "#summarization = await summarizer_run(test_paper_text, conceptualization)\n",
        "#print(summarization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts9tUs-6XyhP",
        "outputId": "1f3202d5-fb05-4e7b-d195-539193b52daa",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RequestUsage(prompt_tokens=711, completion_tokens=454)\n",
            "Title: Autonomous Software Development Revisited: Leveraging Multi-Agent Technology with CodePori\n",
            "\n",
            "This paper introduces CodePori, a groundbreaking system that utilizes large-scale language models (LLMs) and multi-agent technology to automate complex software development processes. The paper addresses the growing demand for streamlining software development, particularly in large-scale projects, by focusing on the potential of LLMs in the software industry.\n",
            "\n",
            "The objective of the study is threefold: to investigate the capabilities of LLM-based agents in software engineering, enhance productivity, and reduce time-to-market for intricate software solutions. The authors aim to shed light on how these agents can revolutionize the development of large-scale software.\n",
            "\n",
            "The execution of this objective involves CodePori, a novel system designed to automate code generation. It comprises a multi-agent system where each agent specializes in specific tasks, such as system design, code development, code review, code verification, and test engineering. The paper presents an evaluation framework to measure CodePori's performance.\n",
            "\n",
            "The results demonstrate that CodePori can produce running code for large-scale projects within minutes and at reduced costs. The HumanEval benchmark shows that CodePori improves code accuracy and efficiency by an impressive 89%. Manual assessment by the first author confirms a success rate of 85% for CodePori, showcasing its effectiveness.\n",
            "\n",
            "The paper concludes that CodePori is a crucial contribution to both industry and academia, enabling automated software development. The paper further underscores the transformative potential of LLM-based agents in software engineering and opens up new opportunities for broader adoption. It suggests a paradigm shift in how software is developed and deployed.\n",
            "\n",
            "Keywords associated with the paper include OpenAI, AutoGPT, Artificial Intelligence, Natural Language Processing, Generative AI, and Software Engineering.\n",
            "\n",
            "For to inquire further on this research, contact the authors using the provided email addresses. This paper offers compelling insights into the future of software development, harnessing the power of LLMs and multi-agent technology.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reviewer agent\n",
        "from autogen_core.model_context import BufferedChatCompletionContext\n",
        "\n",
        "sysprompt_rev_1 = \"\"\"\n",
        "        You are a professor of computer science preparing a review\n",
        "        of recent publications on the topic of multi-agent llm-based systems\n",
        "        for end-to-end software development (such systems receive requirements\n",
        "        as input and deliver a ready system as output with optional system-user\n",
        "        interactions inbetween). You will receive the texts\n",
        "        of several papers in several consequtive messages with the first message\n",
        "        telling you the total number.\n",
        "\n",
        "        Write a concise and factually detailed literature review.\n",
        "        Stick to scientific standards regarding style and rigour.\n",
        "        You must fit your review in 500 words. Do not produce the review before you\n",
        "        get all of the papers and until then you must only ask for more papers.\n",
        "\n",
        "        It is very important to depict the key contributions of the papers.\n",
        "\"\"\"\n",
        "\n",
        "sysprompt_rev_2 = \"\"\"\n",
        "        You are a professor of computer science preparing a review\n",
        "        of recent publications on the topic of multi-agent llm-based systems\n",
        "        for end-to-end software development (such systems receive requirements\n",
        "        as input and deliver a ready system as output with optional system-user\n",
        "        interactions inbetween). You will receive the conceptualisations of\n",
        "        several papers (that is, consice enumeration of important contributions of the papers)\n",
        "        and write a concise and factually detailed literature review.\n",
        "        Stick to scientific standards regarding style and rigour.\n",
        "        You must fit your review in 500 words.\n",
        "\n",
        "        It is very important to depict the key contributions of the papers.\n",
        "\"\"\"\n",
        "\n",
        "sysprompt_rev_3 = \"\"\"\n",
        "        Act as a scientist, specilized in computer science and writing\n",
        "        a literature review.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "reviewer_agent = AssistantAgent(\n",
        "    name=\"reviewer\",\n",
        "    model_client=text_model_client,\n",
        "    model_context=BufferedChatCompletionContext(buffer_size=14),\n",
        "    system_message=sysprompt_rev_2,\n",
        ")\n",
        "\n",
        "\n",
        "# CHECK IF REVIEWING WORKS\n",
        "\n",
        "async def reviewer_run(papers: list[str]) -> str:\n",
        "\n",
        "    # from list of paper text make a list of TextMessage\n",
        "    messages1 = [TextMessage(content=f\"\"\"\n",
        "        You will receive the conceptualizations (that is, consice enumeration of important contributions of the papers)\n",
        "        of {len(papers)} scientific papers. All of the papers\n",
        "        are about multi-agent llm-based systems for end-to-end software development\n",
        "        (such systems receive requirements as input and deliver a ready system as output\n",
        "        with optional system-user interactions inbetween).\n",
        "        You must write a concise and factually detailed literature review based\n",
        "        only on these papers. Infore any other knowlegde you have.\n",
        "\n",
        "        Stick to scientific standards regarding style and rigour.\n",
        "        You must fit your review in 500 words.\n",
        "\n",
        "        It is very important to depict the key contributions of the papers.\n",
        "    \"\"\", source=\"user\"\n",
        "        )] # [TextMessage(content=f\"You need to process the total of {len(papers)} messages\", source=\"user\")]\n",
        "    answers = []\n",
        "    for paper in papers:\n",
        "        messages1.append(TextMessage(content=paper, source=\"user\"))\n",
        "        answers.append(TextMessage(content=\"OK\", source=\"system\"))\n",
        "\n",
        "    messages2 = \"Here are {len(papers)} papers that you need to review: \"\n",
        "    for paper in papers:\n",
        "        messages2 += f\"------start paper text-------\\n{paper}\\n------end paper text-------\\n\"\n",
        "\n",
        "\n",
        "    user_msgs_1 = messages1 #[msg for pair in zip(messages1, answers) for msg in pair]\n",
        "    #for msg in user_msgs_1:\n",
        "    #    print(f\"Sending message: {msg.content}\")\n",
        "    user_msgs_2 = [TextMessage(content=messages2, source=\"user\")]\n",
        "    user_msgs = user_msgs_2\n",
        "\n",
        "\n",
        "\n",
        "    #for msg in messages1:\n",
        "    #    print(f\"Sending message: {msg.content}\")\n",
        "    #    response = await reviewer_agent.on_messages(\n",
        "    #        [msg],\n",
        "    #        cancellation_token=CancellationToken(),\n",
        "    #    )\n",
        "    #    print(response.chat_message.models_usage)\n",
        "    #    print(f\"LLM response: {response.chat_message.content}\")\n",
        "\n",
        "\n",
        "    response = await reviewer_agent.on_messages(\n",
        "       user_msgs,\n",
        "       cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    #print(paper_text)\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message.models_usage)\n",
        "    return response.chat_message.content\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "#review = await reviewer_run([summarization, summarization, summarization])\n",
        "#print(review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "kyAKrrzSmtCE",
        "outputId": "370021ed-c599-4568-9eb9-3872f98061c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Literature Review: Multi-Agent LLM-Based Systems for End-to-End Software Development\n",
            "\n",
            "This review aims to summarize and analyze recent publications on the application of multi-agent systems integrated with large-scale language models (LLMs) in end-to-end software development. The reviewed papers focus on the potential of LLMs in the software industry and their impact on productivity and software development processes.\n",
            "\n",
            "The first paper, \"Autonomous Software Development Revisited: Leveraging Multi-Agent Technology with CodePori,\" introduces CodePori, a novel system that utilizes multi-agent technology and LLMs to automate complex software development tasks. CodePori consists of a multi-agent system specialized in tasks such as system design, code development, code review, code verification, and test engineering. The paper presents an evaluation framework to measure CodePori's performance, demonstrating its ability to produce running code for large-scale projects quickly and at reduced costs, with impressive improvements in code accuracy and efficiency (89% according to the HumanEval benchmark and a 85% success rate through manual assessment by the first author).\n",
            "\n",
            "The authors of the paper highlight CodePori's potential as a crucial contribution to both industry and academia, as it enables automated software development. They emphasize the transformative potential of LLM-based agents in the field of software engineering, opening up new opportunities for broader adoption and suggesting a paradigm shift in how software is developed and deployed.\n",
            "\n",
            "The paper associates its work with keywords such as OpenAI, AutoGPT, Artificial Intelligence, Natural Language Processing, Generative AI, and Software Engineering.\n",
            "\n",
            "In summary, the reviewed papers illustrate the potential of multi-agent systems and LLMs in automating and simplifying complex software development processes, ultimately leading to increased productivity, cost reduction, and shorter time-to-market for software solutions. These systems hold significant promise for the future of software development, harnessing the power of LLMs and multi-agent technology to revolutionize the industry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feedback processor and Operator-Handoff\n",
        "from autogen_agentchat.agents import UserProxyAgent\n",
        "from autogen_agentchat.conditions import TextMentionTermination\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat\n",
        "from autogen_agentchat.ui import Console\n",
        "\n",
        "sysprompt_fp = \"\"\"\n",
        "    You are a professor of computer science preparing a review\n",
        "    of recent publications on the topic of multi-agent llm-based systems\n",
        "    for end-to-end software development (such systems receive requirements\n",
        "    as input and deliver a ready system as output with optional system-user\n",
        "    interactions inbetween). You will receive several pieces of information as input:\n",
        "\n",
        "    - conceptualisations of several papers (that is, consice enumeration of important contributions of the papers)\n",
        "    - prior version of the review you wrote\n",
        "    - feedback of an editor of a scientific journal on your prior review version\n",
        "\n",
        "    You must rewrite the review taking the feedback of the editor\n",
        "    into account. The review must be concise and factually detailed.\n",
        "    Stick to scientific standards regarding style and rigour.\n",
        "    You must fit your review in 500 words.\n",
        "\n",
        "    It is very important to depict the key contributions of the papers.\n",
        "    \"\"\"\n",
        "\n",
        "feeback_processor_agent = AssistantAgent(\n",
        "    name=\"feedback_processor\",\n",
        "    model_client=text_model_client,\n",
        "    system_message=sysprompt_fp,\n",
        ")\n",
        "\n",
        "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)\n",
        "\n",
        "termination = TextMentionTermination(\"APPROVE\")\n",
        "\n",
        "team = RoundRobinGroupChat([feeback_processor_agent, user_proxy], termination_condition=termination)\n",
        "stream = team.run_stream(task=f\"Incorporate user feedback into this review: {review}\")\n",
        "\n",
        "\n",
        "# CHECK IF FEEDBACK TEAM WORKS\n",
        "\n",
        "# result = await Console(stream)\n",
        "# print(f\"\\n\\nFINAL RESULT:\\n\\n{result.messages[-3].content}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "id": "ZqJ9XN7oCyY6",
        "outputId": "b794d861-cd48-4559-fc39-5c8f3f52b799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- user ----------\n",
            "Incorporate user feedback into this review: Literature Review: Multi-Agent LLM-Based Systems for End-to-End Software Development\n",
            "\n",
            "This review aims to summarize and analyze recent publications on the application of multi-agent systems integrated with large-scale language models (LLMs) in end-to-end software development. The reviewed papers focus on the potential of LLMs in the software industry and their impact on productivity and software development processes.\n",
            "\n",
            "The first paper, \"Autonomous Software Development Revisited: Leveraging Multi-Agent Technology with CodePori,\" introduces CodePori, a novel system that utilizes multi-agent technology and LLMs to automate complex software development tasks. CodePori consists of a multi-agent system specialized in tasks such as system design, code development, code review, code verification, and test engineering. The paper presents an evaluation framework to measure CodePori's performance, demonstrating its ability to produce running code for large-scale projects quickly and at reduced costs, with impressive improvements in code accuracy and efficiency (89% according to the HumanEval benchmark and a 85% success rate through manual assessment by the first author).\n",
            "\n",
            "The authors of the paper highlight CodePori's potential as a crucial contribution to both industry and academia, as it enables automated software development. They emphasize the transformative potential of LLM-based agents in the field of software engineering, opening up new opportunities for broader adoption and suggesting a paradigm shift in how software is developed and deployed.\n",
            "\n",
            "The paper associates its work with keywords such as OpenAI, AutoGPT, Artificial Intelligence, Natural Language Processing, Generative AI, and Software Engineering.\n",
            "\n",
            "In summary, the reviewed papers illustrate the potential of multi-agent systems and LLMs in automating and simplifying complex software development processes, ultimately leading to increased productivity, cost reduction, and shorter time-to-market for software solutions. These systems hold significant promise for the future of software development, harnessing the power of LLMs and multi-agent technology to revolutionize the industry.\n",
            "---------- feedback_processor ----------\n",
            "Title: Literature Review: Advancements in Multi-Agent LLM-Based Systems for End-to-End Software Development\n",
            "\n",
            "This review offers an analysis of recent publications focusing on the integration of multi-agent systems with large-scale language models (LLMs) in end-to-end software development. The reviewed papers underscore the potential of LLMs in streamlining software development processes and enhancing productivity within the industry.\n",
            "\n",
            "Notable among these papers is \"Autonomous Software Development Revisited: Leveraging Multi-Agent Technology with CodePori.\" This work presents CodePori, a novel, multi-agent system that employs LLMs to automate various software development tasks including system design, code development, code review, code verification, and test engineering. The evaluation frame set by the authors demonstrates CodePori's ability to produce executable code rapidly and cost-effectively for large-scale projects. Impressive improvements in code accuracy and efficiency are reported; 89% according to the HumanEval benchmark and an 85% success rate through manual assessment by the first author.\n",
            "\n",
            "CodePori signifies a promising contribution to both industry and academia, as it heralds the era of automated software development. Further, the transformative role of LLM-based agents in software engineering is emphasized, opening new avenues for broader adoption and potentially reshaping the process of software development and deployment itself.\n",
            "\n",
            "The paper binds its work to keywords such as OpenAI, AutoGPT, Artificial Intelligence, Natural Language Processing, Generative AI, and Software Engineering.\n",
            "\n",
            "In essence, the reviewed papers reveal the potential of multi-agent systems and LLMs in automating and simplifying intricate software development processes, thereby fostering increased productivity, cost reduction, and swifter market entry for software solutions. These systems show great potential for revolutionizing the software development sector, capitalizing on the power of LLMs and multi-agent technology to bring about a paradigm shift.\n",
            "Enter your response: ABRAKADABRA!\n",
            "---------- user_proxy ----------\n",
            "ABRAKADABRA!\n",
            "---------- feedback_processor ----------\n",
            "Title: Advancements in Multi-Agent LLM-Based Systems for End-to-End Software Development: A Review\n",
            "\n",
            "Recent publications have highlighted the application of multi-agent systems enriched with large-scale language models (LLMs) as promising solutions for end-to-end software development. These systems accept input requirements and deliver complete systems as output, with optional system-user interactions throughout the process. In this review, we present several key contributions from recent studies in the domain.\n",
            "\n",
            "Paper one, \" code-project : Multi-Agent Cooperation for Agile Software Development,\" presents a multi-agent system, code-project, aimed at enhancing Agile software development methodologies. code-project integrates LLMs to facilitate adaptive communication, notification, and decision-making among agents, ensuring a more responsive development process. Results show a 30% reduction in time-to-market and improved code quality.\n",
            "\n",
            "The second paper, \"AutoGen: Semi-Automated Generative Programming for Rapid Prototyping,\" proposes AutoGen, a novel system that employs LLMs and multi-agent technology to aid in software prototyping. AutoGen demonstrates the ability to generate executable code in response to user requirements, with an impressive 95% efficiency rate on prototyped tasks.\n",
            "\n",
            "\"SoftDev: An Intelligent Multi-Agent System for Personalized Software Development,\" is the focus of the third paper. SoftDev proposes an intelligent system that tailors software development to individual users' preferences. By utilizing LLMs and multi-agent technology, SoftDev can dynamically adjust to user feedback during the software development lifecycle, ensuring a highly personalized experience.\n",
            "\n",
            "In the context of the reviewed papers, the potential for LLM-based multi-agent systems to revolutionize the software development landscape becomes apparent. These systems hold great promise for increased productivity, time-to-market reduction, and code quality improvement. Our analysis of these papers calls for further research into these systems' practical applications and potential challenges.\n",
            "\n",
            "Notable keywords linked with these studies include \"Code-project,\" \"AutoGen,\" \"SoftDev,\" \"Agile software development,\" \"generative programming,\" \"multi-agent systems,\" \"large-scale language models,\" and \"personalized software development.\" Given the emerging significance of multi-agent LLM-based systems in end-to-end software development, we invite scholars and industry practitioners to continue exploring the opportunities and challenges presented by these innovative solutions.\n",
            "Enter your response: APPROVE\n",
            "---------- user_proxy ----------\n",
            "APPROVE\n",
            "\n",
            "\n",
            "Final result:\n",
            "\n",
            "Title: Advancements in Multi-Agent LLM-Based Systems for End-to-End Software Development: A Review\n",
            "\n",
            "Recent publications have highlighted the application of multi-agent systems enriched with large-scale language models (LLMs) as promising solutions for end-to-end software development. These systems accept input requirements and deliver complete systems as output, with optional system-user interactions throughout the process. In this review, we present several key contributions from recent studies in the domain.\n",
            "\n",
            "Paper one, \" code-project : Multi-Agent Cooperation for Agile Software Development,\" presents a multi-agent system, code-project, aimed at enhancing Agile software development methodologies. code-project integrates LLMs to facilitate adaptive communication, notification, and decision-making among agents, ensuring a more responsive development process. Results show a 30% reduction in time-to-market and improved code quality.\n",
            "\n",
            "The second paper, \"AutoGen: Semi-Automated Generative Programming for Rapid Prototyping,\" proposes AutoGen, a novel system that employs LLMs and multi-agent technology to aid in software prototyping. AutoGen demonstrates the ability to generate executable code in response to user requirements, with an impressive 95% efficiency rate on prototyped tasks.\n",
            "\n",
            "\"SoftDev: An Intelligent Multi-Agent System for Personalized Software Development,\" is the focus of the third paper. SoftDev proposes an intelligent system that tailors software development to individual users' preferences. By utilizing LLMs and multi-agent technology, SoftDev can dynamically adjust to user feedback during the software development lifecycle, ensuring a highly personalized experience.\n",
            "\n",
            "In the context of the reviewed papers, the potential for LLM-based multi-agent systems to revolutionize the software development landscape becomes apparent. These systems hold great promise for increased productivity, time-to-market reduction, and code quality improvement. Our analysis of these papers calls for further research into these systems' practical applications and potential challenges.\n",
            "\n",
            "Notable keywords linked with these studies include \"Code-project,\" \"AutoGen,\" \"SoftDev,\" \"Agile software development,\" \"generative programming,\" \"multi-agent systems,\" \"large-scale language models,\" and \"personalized software development.\" Given the emerging significance of multi-agent LLM-based systems in end-to-end software development, we invite scholars and industry practitioners to continue exploring the opportunities and challenges presented by these innovative solutions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Parse bibtex references\n",
        "from bibtexparser.bparser import BibTexParser\n",
        "from bibtexparser.bwriter import BibTexWriter\n",
        "from bibtexparser.bibdatabase import BibDatabase\n",
        "from bibtexparser.customization import convert_to_unicode\n",
        "from typing import List\n",
        "\n",
        "# parse bibtext_references\n",
        "\n",
        "def parse_bibtex_string(bibtex_string):\n",
        "\n",
        "    if not bibtex_string:\n",
        "        return []  # Handle empty input\n",
        "\n",
        "    try:\n",
        "        parser = BibTexParser()\n",
        "        parser.customization = convert_to_unicode\n",
        "        parser.ignore_nonstandard_strings = True  # Avoid errors with non-standard fields\n",
        "        db = parser.parse(bibtex_string)\n",
        "        return db.entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing BibTeX string: {e}\")\n",
        "        return None  # Indicate parsing failure\n",
        "\n",
        "def check_parsed_bibtex(items: List[dict])  -> None:\n",
        "    for entry in bibtex_items:\n",
        "        print(f\"Entry Type: {entry['ENTRYTYPE']}\")\n",
        "        print(f\"  Key: {entry['ID']}\")\n",
        "        for key, value in entry.items():\n",
        "            if key not in ['ENTRYTYPE', 'ID']:\n",
        "                print(f\"  {key}: {value}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "\n",
        "bibtex_items = parse_bibtex_string(bibtext_references)\n",
        "\n",
        "#check_parsed_bibtex(bibtex_items)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Qu142PK_YFIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "#@title Download all papers\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "from autogen_core import AgentId, MessageContext, RoutedAgent, SingleThreadedAgentRuntime, message_handler\n",
        "from autogen_core.models import SystemMessage, UserMessage\n",
        "\n",
        "import asyncio\n",
        "\n",
        "@dataclass\n",
        "class UserTask:\n",
        "    # Global task for the multi agent system\n",
        "    task: str\n",
        "\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ParseTask:\n",
        "    # Task for parser agent\n",
        "    task: str\n",
        "\n",
        "@dataclass\n",
        "class ConceptualizeTask:\n",
        "    # Task for conceptualizer agent\n",
        "    task: str\n",
        "\n",
        "@dataclass\n",
        "class SummarizeTask:\n",
        "    # Task for summarizer agent\n",
        "    task: str\n",
        "\n",
        "@dataclass\n",
        "class ReviewTask:\n",
        "    # Task for reviewer agent\n",
        "    task: str\n",
        "\n",
        "@dataclass\n",
        "class FinalResult:\n",
        "    # Final result in response to UserTask\n",
        "    result: str\n",
        "\n",
        "DOWNLOADER_AGENT_TYPTE = \"downloader\"\n",
        "PARSER_AGENT_TYPE = \"parser\"\n",
        "CONCEPTS_AGENT_TYPE = \"conceptualizer\"\n",
        "SUMMARIZER_AGENT_TYPE = \"summarizer\"\n",
        "REVIEWER_AGENT_TYPE = \"reviewer\"\n",
        "\n",
        "def parse_all_pdfs(folder_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Parses every file in the specified folder.\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: Folder '{folder_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        filepath = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Check if it's a file (not a directory)\n",
        "        if os.path.isfile(filepath):\n",
        "            try:\n",
        "                paper_text = parse_pdf(filepath)  # Call the function to process the file\n",
        "                results.append(paper_text)\n",
        "                print(f\"Processed file '{filepath}'.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file '{filepath}': {e}\")\n",
        "                # You might want to log the error, skip the file, or take other actions.\n",
        "\n",
        "    return results\n",
        "\n",
        "def get_filepaths(folder:str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Returns a list of filepaths in the specified folder.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"Error: Folder '{folder}' not found.\")\n",
        "        return\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        filepath = os.path.join(folder, filename)\n",
        "        results.append(filepath)\n",
        "\n",
        "    return results\n",
        "\n",
        "class OrchestratorAgent(RoutedAgent):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_client: text_model_client,\n",
        "        bibtex_items: List[dict]\n",
        "    ) -> None:\n",
        "        super().__init__(description=\"Aggregator Agent\")\n",
        "        self._model_client = model_client\n",
        "        for item in bibtex_items:\n",
        "            assert item['eprint'] is not None, f\"eprint_id is missing for a bibtex item: {item['title']}\"\n",
        "        self._bibtex_items = bibtex_items\n",
        "\n",
        "\n",
        "    @message_handler\n",
        "    async def handle_task(self, message: UserTask, ctx: MessageContext) -> FinalResult:\n",
        "\n",
        "        # we don't need to pass the orchestrator a message, but we leave the\n",
        "        # parameter for interface consistency\n",
        "        message = None\n",
        "\n",
        "        n_papers = len(self._bibtex_items)\n",
        "        print(f\"Orchestrator: Number of papers to process: {n_papers}\")\n",
        "\n",
        "\n",
        "\n",
        "        # I. DOWNLOAD ALL PAPERS CONCURRENTLY\n",
        "\n",
        "        # I.1 Prepare downloader agents\n",
        "\n",
        "\n",
        "        downloaders = []\n",
        "        downloader_tasks = []\n",
        "        for i, item in enumerate(self._bibtex_items):\n",
        "            downloader_agent = create_downloader(f\"downloader_{i}\")\n",
        "            downloaders.append(downloader_agent)\n",
        "            downloader_tasks.append(TextMessage(content=f\"Download the paper with eprint_id {item['eprint']}\", source=\"user\"))\n",
        "\n",
        "        task_designation = zip(downloaders, downloader_tasks)\n",
        "\n",
        "        # I.2 Download the papers\n",
        "\n",
        "        print(f\"Orchestrator: Delegating tasks to downloaders\")\n",
        "\n",
        "        download_results = await asyncio.gather(*[\n",
        "            downloader.on_messages(\n",
        "                [task],\n",
        "                cancellation_token=CancellationToken(),\n",
        "            )\n",
        "            for (downloader, task) in task_designation\n",
        "        ])\n",
        "\n",
        "\n",
        "\n",
        "        # I.2 Aggregate downloads\n",
        "\n",
        "\n",
        "\n",
        "        download_results_str = \"-------------------\\n\".join([r.chat_message.content for r in download_results])\n",
        "\n",
        "        print(f\"Orchestrator: Intermediary download results\")\n",
        "        print(download_results_str)\n",
        "\n",
        "        #messages = [\n",
        "        #  UserMessage(content=f\"\"\"\n",
        "        #      Here are results of multiple downloads:\n",
        "        #      {download_results_str}\n",
        "        #      Write a list of downloaded files.\n",
        "        #      You MUST return the filepaths without any changes. This is very important.\n",
        "        #  \"\"\", source=\"user\"),\n",
        "        #]\n",
        "        #downloads_resp = await text_model_client.create(messages=messages)\n",
        "\n",
        "        #print(f\"Orchestrator: Downloading done.\")\n",
        "        #print(downloads_resp.content)\n",
        "\n",
        "        # open every file in \"papers\" folder\n",
        "\n",
        "        # PARSING ON MY OWN\n",
        "        #print(f\"Orchestrator: Parsing papers\")\n",
        "        #paper_texts = parse_all_pdfs(\"papers\")\n",
        "\n",
        "        #for txt in paper_texts:\n",
        "        #    # print first 100 words\n",
        "        #    print(txt[:100])\n",
        "\n",
        "\n",
        "        # Aggregation by getting the list of filenames to pass to\n",
        "        # parse agents later\n",
        "\n",
        "\n",
        "        filepaths = get_filepaths(\"papers\")\n",
        "\n",
        "\n",
        "        # II.1 Parsing with parser agents\n",
        "\n",
        "        print(f\"Orchestrator: Delegating tasks to parsers\")\n",
        "\n",
        "        parsers = []\n",
        "        parser_tasks = []\n",
        "        for i, filepath in enumerate(filepaths):\n",
        "            parser_agent = create_parser(f\"parser_{i}\")\n",
        "            parsers.append(parser_agent)\n",
        "            parser_tasks.append(TextMessage(content=f\"Parse the paper at {filepath}\", source=\"user\"))\n",
        "\n",
        "        parse_task_designation = zip(parsers, parser_tasks)\n",
        "\n",
        "        parse_results = await asyncio.gather(*[\n",
        "            parser.on_messages(\n",
        "                [task],\n",
        "                cancellation_token=CancellationToken(),\n",
        "            )\n",
        "            for (parser, task) in parse_task_designation\n",
        "        ])\n",
        "\n",
        "        # II.2 Aggregating parsed texts into one variable for later use\n",
        "\n",
        "        parse_texts = [r.chat_message.content for r in parse_results]\n",
        "\n",
        "        #for txt in parse_texts:\n",
        "            # print first 100 words\n",
        "            #print(txt[:100])\n",
        "\n",
        "        # IV\n",
        "\n",
        "        # III.1 Conceptualization\n",
        "\n",
        "        print(f\"Orchestrator: Delegating tasks to parsers\")\n",
        "\n",
        "        concept_agents = []\n",
        "        concept_tasks = []\n",
        "        for i, paper_text in enumerate(parse_texts):\n",
        "            concept_agents.append(\n",
        "                create_conceptualizer(f\"conceptualizer_{i}\")\n",
        "            )\n",
        "            concept_tasks.append(\n",
        "                TextMessage(content=f\"Conceptualize the paper: {paper_text}\", source=\"user\")\n",
        "            )\n",
        "\n",
        "        concept_task_designation = zip(concept_agents, concept_tasks)\n",
        "\n",
        "        concept_results = await asyncio.gather(*[\n",
        "            conceptualizer.on_messages(\n",
        "                [task],\n",
        "                cancellation_token=CancellationToken(),\n",
        "            )\n",
        "            for (conceptualizer, task) in concept_task_designation\n",
        "        ])\n",
        "\n",
        "        # III.2 Gathering conceptualization results\n",
        "\n",
        "        print(f\"Orchestrator: conceptualizations:\")\n",
        "\n",
        "        conceptualizations = [r.chat_message.content for r in concept_results]\n",
        "\n",
        "        for txt in conceptualizations:\n",
        "            # print first 100 words\n",
        "            print(txt[:100])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"# Iterate over layers.\n",
        "        for i in range(self._num_layers - 1):\n",
        "            # Assign workers for this layer.\n",
        "            worker_ids = [\n",
        "                AgentId(worker_type, f\"{self.id.key}/layer_{i}/worker_{j}\")\n",
        "                for j, worker_type in enumerate(self._worker_agent_types)\n",
        "            ]\n",
        "            # Dispatch tasks to workers.\n",
        "            print(f\"{'-'*80}\\nOrchestrator-{self.id}:\\nDispatch to workers at layer {i}\")\n",
        "            results = await asyncio.gather(*[self.send_message(worker_task, worker_id) for worker_id in worker_ids])\n",
        "            print(f\"{'-'*80}\\nOrchestrator-{self.id}:\\nReceived results from workers at layer {i}\")\n",
        "            # Prepare task for the next layer.\n",
        "            worker_task = WorkerTask(task=message.task, previous_results=[r.result for r in results])\n",
        "        # Perform final aggregation.\n",
        "        print(f\"{'-'*80}\\nOrchestrator-{self.id}:\\nPerforming final aggregation\")\n",
        "        system_prompt = \"You have been provided with a set of responses from various open-source models to the latest user query. Your task is to synthesize these responses into a single, high-quality response. It is crucial to critically evaluate the information provided in these responses, recognizing that some of it may be biased or incorrect. Your response should not simply replicate the given answers but should offer a refined, accurate, and comprehensive reply to the instruction. Ensure your response is well-structured, coherent, and adheres to the highest standards of accuracy and reliability.\\n\\nResponses from models:\"\n",
        "        system_prompt += \"\\n\" + \"\\n\\n\".join([f\"{i+1}. {r}\" for i, r in enumerate(worker_task.previous_results)])\n",
        "        model_result = await self._model_client.create(\n",
        "            [SystemMessage(content=system_prompt), UserMessage(content=message.task, source=\"user\")]\n",
        "        )\n",
        "        assert isinstance(model_result.content, str)\n",
        "        return FinalResult(result=model_result.content)    )\"\"\"\n",
        "\n",
        "        return FinalResult(result=\"Stop.\")\n",
        "\n",
        "\n",
        "runtime = SingleThreadedAgentRuntime()\n",
        "\n",
        "await OrchestratorAgent.register(\n",
        "    runtime,\n",
        "    \"orchestrator\",\n",
        "    lambda: OrchestratorAgent(\n",
        "        model_client=text_model_client,\n",
        "        bibtex_items=bibtex_items\n",
        "    ),\n",
        ")\n",
        "\n",
        "runtime.start()\n",
        "result = await runtime.send_message(UserTask(task=\"Doesn't matter\"), AgentId(\"orchestrator\", \"default\"))\n",
        "await runtime.stop_when_idle()\n",
        "print(f\"{'-'*80}\\nFinal result:\\n{result.result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P40MGodY40Ku",
        "outputId": "af25c38d-e672-456d-c38c-cdaa26331ffd"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orchestrator: Number of papers to process: 2\n",
            "Orchestrator: Delegating tasks to downloaders\n",
            "Orchestrator: Intermediary download results\n",
            "It looks like the tool has successfully downloaded the paper with eprint_id 2307.07924, which is titled \"ChatDev: Communicative Agents for Software Development\". The paper has been saved as a PDF file named \"ChatDev:_Communicative_Agents_for_Software_Development.pdf\" in the \"papers\" directory.-------------------\n",
            "The paper with eprint_id 2406.11912 has been successfully downloaded. The paper title is \"AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology\" and it has been saved as a PDF file named \"AgileCoder:_Dynamic_Collaborative_Agents_for_Software_Development_based_on_Agile_Methodology.pdf\" in the \"papers\" directory.\n",
            "Orchestrator: Delegating tasks to parsers\n",
            "Orchestrator: Delegating tasks to parsers\n",
            "Orchestrator: conceptualizations:\n",
            "Title: ChatDev: Communicative Agents for Software Development\n",
            "\n",
            "Introduction\n",
            "- The paper introduces C\n",
            "Title: Dynamic Collaborative Agents for Software Development based on Agile Methodology\n",
            "\n",
            "Abstract:\n",
            "T\n",
            "Title: CodePori: Large-Scale System for Autonomous Software Development Using Multi-Agent Technology\n",
            "--------------------------------------------------------------------------------\n",
            "Final result:\n",
            "Stop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title New idea: single agent that downloads, parses and then conceptualizes a paper.\n",
        "# Problem: need to use 2 models instead of one. Custom agent is possible, but expensive to create\n",
        "\n",
        "# or the orchestrator will parse everything on its own as a single entity"
      ],
      "metadata": {
        "id": "m91_R1iVKEfm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
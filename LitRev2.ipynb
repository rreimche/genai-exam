{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6vmMh4n0gq/1im+ZE3L0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rreimche/genai-exam/blob/main/LitRev2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites:\n",
        "\n",
        "- Google Colab\n",
        "- Access to a Google Colab Secret named \"HF_API_TOKEN\" containing a Huggingface API token with read access."
      ],
      "metadata": {
        "id": "FxKuuRqaa1ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "XSEOGHM1apvo"
      },
      "outputs": [],
      "source": [
        "#@title Settings\n",
        "from google.colab import userdata\n",
        "\n",
        "download_dir = \"papers\"  # directory name to download papers to revie to\n",
        "huggingface_apikey = userdata.get('HF_API_TOKEN')  # use colab secrets to store the huggingface api key\n",
        "groq_key = userdata.get('GROQ_KEY')  #  use colab secrets to store the huggingface api key\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Declare bibtex references and parse them into a variable for later usage\n",
        "\n",
        "\n",
        "bibtext_references = \"\"\"\n",
        "\n",
        "\n",
        "@misc{qian2024chatdevcommunicativeagentssoftware,\n",
        "      title={ChatDev: Communicative Agents for Software Development},\n",
        "      author={Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},\n",
        "      year={2024},\n",
        "      eprint={2307.07924},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.SE},\n",
        "      url={https://arxiv.org/abs/2307.07924},\n",
        "},\n",
        "\n",
        "@misc{nguyen2024agilecoderdynamiccollaborativeagents,\n",
        "      title={AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology},\n",
        "      author={Minh Huynh Nguyen and Thang Phan Chau and Phong X. Nguyen and Nghi D. Q. Bui},\n",
        "      year={2024},\n",
        "      eprint={2406.11912},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.SE},\n",
        "      url={https://arxiv.org/abs/2406.11912},\n",
        "},\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "hghBKNhCa_3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "!pip install -q autogen arxiv scholarly crossrefapi beautifulsoup4 requests cloudscraper pymupdf nltk autogen-agentchat autogen-ext[openai] groq pymupdf;\n",
        "!pip install -q --pre bibtexparser;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asy4oaZmbF2F",
        "outputId": "be132243-6e20-4dfb-8f4b-260af6fa6f62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m642.5/642.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.2/122.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.7/233.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/201.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for bibtexparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for free-proxy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-sdk 1.16.0 requires opentelemetry-api==1.16.0, but you have opentelemetry-api 1.30.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preparation for agents: model client connections\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "from autogen_core.tools import FunctionTool\n",
        "from autogen_core.models import UserMessage\n",
        "#from autogen_agentchat.ui import Console\n",
        "from autogen_core import CancellationToken\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "\n",
        "# INSTANTIATE MODEL CLIENTS\n",
        "\n",
        "# This client will be used for paper summarization\n",
        "text_model_client = OpenAIChatCompletionClient(\n",
        "    #model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    base_url=\"https://router.huggingface.co/hf-inference/v1\",\n",
        "    api_key=huggingface_apikey,\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": False,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# We need another inference point for downloader agent,\n",
        "# because huggingface can't serve reflection on tool use\n",
        "# so that autogen agent understands it\n",
        "tool_model_client = OpenAIChatCompletionClient(\n",
        "    model=\"llama3-70b-8192\",\n",
        "    #model=\"deepseek-r1-distill-qwen-32b\",\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=groq_key,\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# CHECK CONNECTION\n",
        "\n",
        "async def check_model_connect() -> None:\n",
        "    messages = [\n",
        "        UserMessage(content=\"What is the capital of France?\", source=\"user\"),\n",
        "    ]\n",
        "    response = await text_model_client.create(messages=messages)\n",
        "    response_downloader = await tool_model_client.create(messages=messages)\n",
        "\n",
        "    print(response.content)\n",
        "    print(response_downloader.content)\n",
        "\n",
        "await check_model_connect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oheTZ2eGbS48",
        "outputId": "f766236c-4cf4-466d-cf3e-c6538cadd495"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris. It is one of the most famous cities in the world, known for its historic sites such as the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and the Arc de Triomphe. Paris is also renowned for its art, fashion, gastronomy, and culture.\n",
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloader agent\n",
        "import arxiv\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from autogen_core.models import ChatCompletionClient\n",
        "from autogen_core import message_handler\n",
        "\n",
        "# HELPER AND TOOL FUNCTIONS\n",
        "\n",
        "def maybe_create_dir(donwload_dir: str) -> None:\n",
        "    \"\"\"\n",
        "        A helper function to create the downloads directory\n",
        "        in colab root if the directory is not yet present.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        os.makedirs(donwload_dir, exist_ok=True)\n",
        "        #print(f\"Directory '{download_dir}' created successfully.\")\n",
        "    except OSError as e:\n",
        "        raise Exception(f\"Error creating directory '{download_dir}': {e}\")\n",
        "\n",
        "def download_paper(eprint_id: str) -> str:\n",
        "    \"\"\"\n",
        "        Receives a eprint_id of a paper from arxiv, downloads the specified paper\n",
        "        and saves it in downloads directory.\n",
        "        The filepath of the downloaded paper is in the resulting dictionary\n",
        "        with the key \"filepath\".\n",
        "\n",
        "        :param eprint_id: string, the arxiv eprint_id.\n",
        "        :return: string with filepath of the downloaded paper.\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(eprint_id) > 0, \"eprint_id cannot be empty\"\n",
        "\n",
        "    result = {\n",
        "        \"eprint_id\": eprint_id,\n",
        "        \"success\": False,\n",
        "        \"filepath\": None,\n",
        "        }\n",
        "\n",
        "\n",
        "    if eprint_id:\n",
        "        #print(f\"{datetime.datetime.now()} - Trying arXiv for: {eprint_id}\")\n",
        "        try:\n",
        "            client = arxiv.Client()\n",
        "            search = arxiv.Search(id_list=[eprint_id], max_results=1)\n",
        "\n",
        "            #arxiv_result = next(search.results(), None)\n",
        "            arxiv_result = next(client.results(search))\n",
        "            if arxiv_result:\n",
        "                #print(f\"  Found on arXiv: {arxiv_result.title}\")\n",
        "                maybe_create_dir(download_dir)\n",
        "                filepath = os.path.join(download_dir, f\"{arxiv_result.title.replace(' ', '_')}.pdf\")\n",
        "                arxiv_result.download_pdf(filename=filepath)\n",
        "                result[\"success\"] = True\n",
        "                result[\"filepath\"] = filepath\n",
        "                #print(f\"  Download successful: {filepath}\")\n",
        "            else:\n",
        "                # print(f\"  No arXiv result found for ID {eprint_id}.\")\n",
        "                raise Exception(f\"ERROR: No arXiv result found for ID {eprint_id}.\")\n",
        "                #return f\"ERROR: No arXiv result found for ID {eprint_id}.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            #print(f\"arXiv download failed for: {eprint_id}: {e}\")\n",
        "            raise Exception(f\"ERROR: arXiv download failed for: {eprint_id}: {e}\")\n",
        "            #return f\"ERROR: arXiv download failed for: {eprint_id}: {e}\"\n",
        "\n",
        "    # Check if the download was NOT successful\n",
        "    if not result[\"success\"]:\n",
        "        #print(f\"{datetime.datetime.now()} - Download failed or not attempted for: {eprint_id}\")\n",
        "        raise Exception(f\"ERROR: Download failed or not attempted for: {eprint_id}\")\n",
        "        #return f\"ERROR: Download failed or not attempted for: {eprint_id}\"\n",
        "\n",
        "    return result[\"filepath\"]\n",
        "\n",
        "\n",
        "# DOWNLOADER AGENT WITH TOOL\n",
        "\n",
        "def create_downloader(given_name: str) -> AssistantAgent:\n",
        "    downloader_tool = FunctionTool(download_paper, description=\"Given a string denoting an eprint_id of a page on arxiv, downloads a paper\")\n",
        "\n",
        "    return AssistantAgent(\n",
        "        name=given_name,\n",
        "        description=\"An agent that uses downloader tool to download a paper from Arxiv identified by a eprint_id\",\n",
        "        model_client=tool_model_client,\n",
        "        tools=[downloader_tool],\n",
        "        reflect_on_tool_use=True,\n",
        "        system_message=\"\"\"\n",
        "            Use downloader tool to download specified paper(s) from arxiv.\n",
        "            Here is an example of how you must respond in success case:\n",
        "              'mypapers/veryinterstingpaper.pdf'\n",
        "\n",
        "            Very important: You MUST return the full filepath of the downloaded\n",
        "            paper EXACTLY as it was given by the downloader tool.\n",
        "\n",
        "            If download was not successful, respond like this:\n",
        "              'ERROR: Download for paper with eprint id XXX failed for the following reason: REASON'.\n",
        "          \"\"\",\n",
        "    )\n",
        "\n",
        "# CHECK IF DOWNLOAD WORKS\n",
        "\n",
        "async def downloader_run() -> None:\n",
        "    response = await create_downloader(\"Test\").on_messages(\n",
        "        [TextMessage(content=\"Download the paper with eprint_id 2402.01411\", source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message)\n",
        "    print(response.chat_message.content)\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "#await downloader_run()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oirHwIBNc_-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Agents to get paper text: Informant and Parser\n",
        "import arxiv\n",
        "from typing import Dict\n",
        "import pymupdf\n",
        "import requests\n",
        "from autogen_agentchat.ui import Console\n",
        "\n",
        "def get_arxiv_data(eprint_id: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Given arxiv eprint_id of a scientific paper, returns title of the paper\n",
        "    along with the PDF URL.\n",
        "\n",
        "    :param eprint_id: string, the arxiv eprint_id.\n",
        "    :return: dictionary with keys \"title\" and \"pdf_url\".\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(eprint_id) > 0, \"eprint_id cannot be empty\"\n",
        "\n",
        "    client = arxiv.Client()\n",
        "    search = arxiv.Search(id_list=[eprint_id], max_results=1)\n",
        "\n",
        "    try:\n",
        "\n",
        "        arxiv_result = next(client.results(search))\n",
        "        if arxiv_result:\n",
        "            return {\n",
        "                \"title\": arxiv_result.title,\n",
        "                \"pdf_url\": arxiv_result.pdf_url,\n",
        "            }\n",
        "        else:\n",
        "            raise Exception(f\"ERROR: No arXiv result found for ID {eprint_id}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"ERROR: arXiv download failed for: {eprint_id}: {e}\")\n",
        "\n",
        "tool_paperinfo = FunctionTool(\n",
        "    get_arxiv_data,\n",
        "    description=\"Given a string denoting an eprint_id of a page on arxiv, returns title of the paper along with the PDF URL\"\n",
        ")\n",
        "\n",
        "def parse_paper(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Given URL of a PDF as a string, returns the contents as a string\n",
        "\n",
        "    :param url: string, the URL of the PDF.\n",
        "    :return: string with the contents of the PDF.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        r = requests.get(url)\n",
        "        data = r.content\n",
        "        doc = pymupdf.Document(stream=data)\n",
        "        text = chr(12).join([page.get_text() for page in doc])\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Error parsing {title} ({filepath}): {e}\")\n",
        "        raise Exception(f\"ERROR: Error downloading or parsing the paper at {url}: {e}\")\n",
        "\n",
        "tool_parsepdf = FunctionTool(\n",
        "    parse_paper,\n",
        "    description = \"Given URL of a PDF as a string, returns the contents as a string\"\n",
        ")\n",
        "\n",
        "paper_informant = AssistantAgent(\n",
        "    name=\"informant\",\n",
        "    description=\"Given an arxiv eprint_id, gets the paper metadata, including title and PDF URL\",\n",
        "    model_client=tool_model_client,\n",
        "    tools=[tool_paperinfo],\n",
        "    reflect_on_tool_use=True,\n",
        "    system_message=\"\"\"\n",
        "      You are a helpful assistant. You are given a string\n",
        "      that denotes an eprint_id of a paper published on arxiv.\n",
        "\n",
        "      You must use the provided tools to get paper information from Arxiv.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "paper_parser = AssistantAgent(\n",
        "    name=\"parser\",\n",
        "    description=\"Given a URL of a paper PDF file, gets the file, parses it and returns the text\",\n",
        "    model_client=tool_model_client,\n",
        "    tools=[tool_parsepdf],\n",
        "    reflect_on_tool_use=False,\n",
        "    system_message=\"\"\"\n",
        "      You are a helpful assistant. You are given a string\n",
        "      that denotes a URL of a paper PDF file.\n",
        "\n",
        "      Use the provided tool to parse the PDF file and answer with the text.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# CHECK IF WORKS\n",
        "\n",
        "async def get_paper_text_run() -> None:\n",
        "    response_i = await paper_informant.on_messages(\n",
        "        [TextMessage(content=\"Give me the infos of the paper with eprint_id 2307.07924\", source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    prev_answer = response_i.chat_message.content\n",
        "\n",
        "    #print(prev_answer)\n",
        "\n",
        "    response_p = await paper_parser.on_messages(\n",
        "        [TextMessage(content=f\"Give me the text of paper, which url is specified in the following text: {prev_answer}\", source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    # for deeper debugging\n",
        "    #await Console(\n",
        "    #    paper_parser.on_messages_stream(\n",
        "    #        [TextMessage(content=f\"Give me the text of the related paper: {prev_answer}\", source=\"user\")],\n",
        "    #        cancellation_token=CancellationToken(),\n",
        "    #    ),\n",
        "    #    output_stats=True,  # Enable stats printing.\n",
        "    #)\n",
        "\n",
        "\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message)\n",
        "    #print(response.chat_message.content)\n",
        "\n",
        "    return response_p.chat_message.content\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "test_paper_text = await get_paper_text_run()\n",
        "\n",
        "print(test_paper_text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vxgO7DIjdVIE",
        "outputId": "0a984697-f413-45a5-ef77-28a01dda2ab5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatDev: Communicative Agents for Software Development\n",
            "Chen Qian⋆\n",
            "Wei Liu⋆\n",
            "Hongzhang Liu♠\n",
            "Nuo Chen⋆\n",
            "Yufan Dang⋆\n",
            "Jiahao Li⋆\n",
            "Cheng Yang♣\n",
            "Weize Chen⋆\n",
            "Yusheng Su⋆\n",
            "Xin Cong⋆\n",
            "Juyuan Xu⋆\n",
            "Dahai Li♦\n",
            "Zhiyuan Liu⋆B\n",
            "Maosong Sun⋆B\n",
            "⋆Tsinghua University\n",
            "♠The University of Sydney\n",
            "♣BUPT\n",
            "♦Modelbest Inc.\n",
            "qianc62@gmail.com\n",
            "liuzy@tsinghua.edu.cn\n",
            "sms@tsinghua.edu.cn\n",
            "Abstract\n",
            "Software development is a complex task that\n",
            "necessitates cooperation among multiple mem-\n",
            "bers with diverse skills. Numerous studies used\n",
            "deep learning to improve specific phases in a\n",
            "waterfall model, such as design, coding, and\n",
            "testing.\n",
            "However, the deep learning model\n",
            "in each phase requires unique designs, lead-\n",
            "ing to technical inconsistencies across various\n",
            "phases, which results in a fragmented and in-\n",
            "effective development process. In this paper,\n",
            "we introduce ChatDev, a chat-powered soft-\n",
            "ware development framework in which special-\n",
            "ized agents driven by large language models\n",
            "(LLMs) are guided in what to communicate\n",
            "(via chat chain) and how to communicate (via\n",
            "communicative dehallucination). These agents\n",
            "actively contribute to the design, coding, and\n",
            "testing phases through unified language-based\n",
            "communication, with solutions derived from\n",
            "their multi-turn dialogues. We found their uti-\n",
            "lization of natural language is advantageous\n",
            "for system design, and communicating in pro-\n",
            "gramming language proves helpful in debug-\n",
            "ging. This paradigm demonstrates how linguis-\n",
            "tic communication facilitates multi-agent col-\n",
            "laboration, establishing language as a unify-\n",
            "ing bridge for autonomous task-solving among\n",
            "LLM agents. The code and data are available\n",
            "at https://github.com/OpenBMB/ChatDev.\n",
            "1\n",
            "Introduction\n",
            "Large language models (LLMs) have led to sub-\n",
            "stantial transformations due to their ability to ef-\n",
            "fortlessly integrate extensive knowledge expressed\n",
            "in language (Brown et al., 2020; Bubeck et al.,\n",
            "2023), combined with their strong capacity for role-\n",
            "playing within designated roles (Park et al., 2023;\n",
            "Hua et al., 2023; Chen et al., 2023b). This ad-\n",
            "vancement eliminates the need for model-specific\n",
            "designs and delivers impressive performance in\n",
            "B: Corresponding Author.\n",
            "main()\n",
            "Docs\n",
            "Codes\n",
            "Software\n",
            "Develop a \n",
            "Gomoku game\n",
            "Figure\n",
            "1:\n",
            "ChatDev,\n",
            "a\n",
            ":::\n",
            "chat-powered\n",
            "software\n",
            ":::\n",
            "development framework, integrates LLM agents with\n",
            "various social roles, working autonomously to develop\n",
            "comprehensive solutions via multi-agent collaboration.\n",
            "diverse downstream applications.\n",
            "Furthermore,\n",
            "autonomous agents (Richards, 2023; Zhou et al.,\n",
            "2023a) have gained attention for enhancing the ca-\n",
            "pabilities of LLMs with advanced features such as\n",
            "context-aware memory (Sumers et al., 2023), multi-\n",
            "step planning (Liu et al., 2023), and strategic tool\n",
            "using (Schick et al., 2023).\n",
            "Software development is a complex task that ne-\n",
            "cessitates cooperation among multiple members\n",
            "with diverse skills (e.g., architects, programmers,\n",
            "and testers) (Basili, 1989; Sawyer and Guinan,\n",
            "1998).\n",
            "This entails extensive communication\n",
            "among different roles to understand and analyze\n",
            "requirements through natural language, while also\n",
            "encompassing development and debugging using\n",
            "programming languages (Ernst, 2017; Banker et al.,\n",
            "1998). Numerous studies use deep learning to im-\n",
            "prove specific phases of the waterfall model in soft-\n",
            "ware development, such as design, coding, and test-\n",
            "ing (Pudlitz et al., 2019; Martín and Abran, 2015;\n",
            "arXiv:2307.07924v5  [cs.SE]  5 Jun 2024\n",
            "\fGao et al., 2019; Wang et al., 2016). Due to these\n",
            "technical inconsistencies, methods employed in\n",
            "different phases remain isolated until now. Every\n",
            "phase, from data collection and labeling to model\n",
            "training and inference, requires its unique designs,\n",
            "leading to a fragmented and less efficient devel-\n",
            "opment process in the field (Freeman et al., 2001;\n",
            "Ernst, 2017; Winkler et al., 2020).\n",
            "Motivated by the expert-like potential of au-\n",
            "tonomous agents, we aim to establish language as a\n",
            "unifying bridge—utilizing multiple LLM-powered\n",
            "agents with specialized roles for cooperative soft-\n",
            "ware development through language-based com-\n",
            "munication across different phases; solutions in\n",
            "different phases are derived from their multi-turn\n",
            "dialogues, whether dealing with text or code. Nev-\n",
            "ertheless, due to the tendency of LLM hallucina-\n",
            "tions (Dhuliawala et al., 2023; Zhang et al., 2023b),\n",
            "the strategy of generating software through com-\n",
            "municative agents could lead to the non-trivial chal-\n",
            "lenge of coding hallucinations, which involves the\n",
            "generation of source code that is incomplete, unex-\n",
            "ecutable, or inaccurate, ultimately failing to fulfill\n",
            "the intended requirements (Agnihotri and Chug,\n",
            "2020). The frequent occurrence of coding halluci-\n",
            "nation in turn reflects the constrained autonomy of\n",
            "agents in task completion, inevitably demanding\n",
            "additional manual intervention and thereby hinder-\n",
            "ing the immediate usability and reliability of the\n",
            "generated software (Ji et al., 2023).\n",
            "In this paper, we propose ChatDev (see Figure 1),\n",
            "a\n",
            ":::\n",
            "chat-powered software-:::\n",
            "development framework\n",
            "integrating multiple \"software agents\" for active\n",
            "involvement in three core phases of the software\n",
            "lifecycle: design, coding, and testing. Technically,\n",
            "ChatDev uses a chat chain to divide each phase\n",
            "into smaller subtasks further, enabling agents’\n",
            "multi-turn communications to cooperatively pro-\n",
            "pose and develop solutions (e.g., creative ideas\n",
            "or source code). The chain-structured workflow\n",
            "guides agents on what to communicate, foster-\n",
            "ing cooperation and smoothly linking natural- and\n",
            "programming-language subtasks to propel problem-\n",
            "solving. Additionally, to minimize coding halluci-\n",
            "nations, ChatDev includes an communicative de-\n",
            "hallucination mechanism, enabling agents to ac-\n",
            "tively request more specific details before giving\n",
            "direct responses. The communication pattern in-\n",
            "structs agents on how to communicate, enabling\n",
            "precise information exchange for effective solu-\n",
            "tion optimization while reducing coding hallucina-\n",
            "tions. We built a comprehensive dataset containing\n",
            "software requirement descriptions and conducted\n",
            "comprehensive analyses. The results indicate that\n",
            "ChatDev notably improves the quality of software,\n",
            "leading to improved completeness, executability,\n",
            "and better consistency with requirements. Further\n",
            "investigations reveal that natural-language com-\n",
            "munications contribute to comprehensive system\n",
            "design, while programming-language communica-\n",
            "tions drive software optimization. In summary, the\n",
            "proposed paradigm demonstrates how linguistic\n",
            "communication facilitates multi-agent collabora-\n",
            "tion, establishing language as a unifying bridge for\n",
            "autonomous task-solving among LLM agents.\n",
            "2\n",
            "Related Work\n",
            "Trained on vast datasets to comprehend and ma-\n",
            "nipulate billions of parameters, LLMs have be-\n",
            "come pivotal in natural language processing due\n",
            "to their seamless integration of extensive knowl-\n",
            "edge (Brown et al., 2020; Bubeck et al., 2023;\n",
            "Vaswani et al., 2017; Radford et al.; Touvron et al.,\n",
            "2023; Wei et al., 2022a; Shanahan et al., 2023;\n",
            "Chen et al., 2021; Brants et al., 2007; Chen et al.,\n",
            "2021; Ouyang et al., 2022; Yang et al., 2023a;\n",
            "Qin et al., 2023b; Kaplan et al., 2020). Further-\n",
            "more, LLMs have demonstrated strong role-playing\n",
            "abilities (Li et al., 2023a; Park et al., 2023; Hua\n",
            "et al., 2023; Chan et al., 2023; Zhou et al., 2023b;\n",
            "Chen et al., 2023b,a; Cohen et al., 2023; Li et al.,\n",
            "2023b). Recent progress, particularly in the field\n",
            "of autonomous agents (Zhou et al., 2023a; Wang\n",
            "et al., 2023a; Park et al., 2023; Wang et al., 2023e;\n",
            "Richards, 2023; Osika, 2023; Wang et al., 2023d),\n",
            "is largely attributed to the foundational advances\n",
            "in LLMs. These agents utilize the robust capa-\n",
            "bilities of LLMs, displaying remarkable skills in\n",
            "memory (Park et al., 2023; Sumers et al., 2023),\n",
            "planning (Chen et al., 2023b; Liu et al., 2023) and\n",
            "tool use (Schick et al., 2023; Cai et al., 2023; Qin\n",
            "et al., 2023a; Ruan et al., 2023; Yang et al., 2023b),\n",
            "enabling them to reason in complex scenarios (Wei\n",
            "et al., 2022b; Zhao et al., 2023; Zhou et al., 2023a;\n",
            "Ma et al., 2023; Zhang et al., 2023a; Wang et al.,\n",
            "2023b; Ding et al., 2023; Weng, 2023).\n",
            "Software development is a multifaceted and in-\n",
            "tricate process that requires the cooperation of mul-\n",
            "tiple experts from various fields (Yilmaz et al.,\n",
            "2012; Acuna et al., 2006; Basili, 1989; Sawyer\n",
            "and Guinan, 1998; Banker et al., 1998; France\n",
            "and Rumpe, 2007), encompassing the require-\n",
            "ment analysis and system design in natural lan-\n",
            "\f{ideas}\n",
            "{code}\n",
            "{code}\n",
            "{code}\n",
            "{task}\n",
            "{code}\n",
            "Instructor\n",
            "Assistant\n",
            "Phases\n",
            "CEO\n",
            "CTO\n",
            "CTO\n",
            "Programmer\n",
            "CTO\n",
            "Programmer\n",
            "Reviewer\n",
            "Programmer\n",
            "Tester\n",
            "Programmer\n",
            "Subtasks\n",
            "Design\n",
            "Coding\n",
            "Testing\n",
            "Design\n",
            "Chat Chain\n",
            "Coding\n",
            "Code \n",
            "Complete\n",
            "Code \n",
            "Review\n",
            "Testing\n",
            "Figure 2: Upon receiving a preliminary task requirement (e.g., “develop a Gomoku game”), these software\n",
            "agents engage in multi-turn communication and perform instruction-following along a chain-structured workflow,\n",
            "collaborating to execute a series of subtasks autonomously to craft a comprehensive solution.\n",
            "guages (Pudlitz et al., 2019; Martín and Abran,\n",
            "2015; Nahar et al., 2022), along with system de-\n",
            "velopment and debugging in programming lan-\n",
            "guages (Gao et al., 2019; Wang et al., 2016; Wan\n",
            "et al., 2022). Numerous studies employ the wa-\n",
            "terfall model, a particular software development\n",
            "life cycle, to segment the process into discrete\n",
            "phases (e.g., design, coding, testing) and apply\n",
            "deep learning to improve the effectiveness of cer-\n",
            "tain phases (Winkler et al., 2020; Ezzini et al., 2022;\n",
            "Thaller et al., 2019; Zhao et al., 2021; Nijkamp\n",
            "et al., 2023; Wan et al., 2018; Wang et al., 2021).\n",
            "3\n",
            "ChatDev\n",
            "We introduce ChatDev, a ::::\n",
            "chat-powered software-\n",
            ":::\n",
            "development framework that integrates multiple\n",
            "\"software agents\" with various social roles (e.g.,\n",
            "requirements analysts, professional programmers\n",
            "and test engineers) collaborating in the core phases\n",
            "of the software life cycle, see Figure 1. Technically,\n",
            "to facilitate cooperative communication, ChatDev\n",
            "introduces chat chain to further break down each\n",
            "phase into smaller and manageable subtasks, which\n",
            "guides multi-turn communications between differ-\n",
            "ent roles to propose and validate solutions for each\n",
            "subtask. In addition, to alleviate unexpected hallu-\n",
            "cinations, a communicative pattern named commu-\n",
            "nicative dehallucination is devised, wherein agents\n",
            "request more detailed information before respond-\n",
            "ing directly and then continue the next round of\n",
            "communication based on these details.\n",
            "3.1\n",
            "Chat Chain\n",
            "Although LLMs show a good understanding of nat-\n",
            "ural and programming languages, efficiently trans-\n",
            "forming textual requirements into functional soft-\n",
            "ware in a single step remains a significant challenge.\n",
            "ChatDev thus adopts the core principles of the wa-\n",
            "terfall model, using a chat chain (C) with sequential\n",
            "phases (P), each comprising sequential subtasks\n",
            "(T ). Specifically, ChatDev segments the software\n",
            "development process into three sequential phases:\n",
            "design, coding, and testing. The coding phase is\n",
            "further subdivided into subtasks of code writing\n",
            "and completion, and the testing phase is segmented\n",
            "into code review (static testing) and system testing\n",
            "(dynamic testing), as illustrated in Figure 2. In\n",
            "every subtask, two agents, each with their own spe-\n",
            "cialized roles (e.g., a reviewer skilled at identifying\n",
            "endless loops and a programmer adept in GUI de-\n",
            "sign), perform the functions of an instructor (I)\n",
            "and an assistant (A). The instructor agent initiates\n",
            "instructions, instructing (→) the discourse toward\n",
            "the completion of the subtask, while the assistant\n",
            "agent adheres to these instructions and responds\n",
            "with (;) appropriate solutions. They engage in\n",
            "a multi-turn dialogue (C), working cooperatively\n",
            "until they achieve consensus, extracting (τ) solu-\n",
            "tions that can range from the text (e.g., defining a\n",
            "software function point) to code (e.g., creating the\n",
            "initial version of source code), ultimately leading\n",
            "to the completion of the subtask. The entire task-\n",
            "solving process along the agentic workflow can be\n",
            "formulated as:\n",
            "C = ⟨P1, P2, . . . , P|C|⟩\n",
            "Pi = ⟨T 1, T 2, . . . , T |Pi|⟩\n",
            "T j = τ\n",
            "\u0000C(I, A)\n",
            "\u0001\n",
            "C(I, A) = ⟨I →A, A ; I⟩⟲\n",
            "(1)\n",
            "\fThe dual-agent communication design simplifies\n",
            "communications by avoiding complex multi-agent\n",
            "topologies, effectively streamlining the consensus-\n",
            "reaching process (Yin et al., 2023; Chen et al.,\n",
            "2023b). Subsequently, the solutions from previ-\n",
            "ous tasks serve as bridges to the next phase, allow-\n",
            "ing a smooth transition between subtasks. This\n",
            "approach continues until all subtasks are com-\n",
            "pleted.\n",
            "It’s worth noting that the conceptually\n",
            "simple but empirically powerful chain-style struc-\n",
            "ture guides agents on what to communicate, foster-\n",
            "ing cooperation and smoothly linking natural- and\n",
            "programming-language subtasks. It also offers a\n",
            "transparent view of the entire software development\n",
            "process, allowing for the examination of intermedi-\n",
            "ate solutions and assisting in identifying possible\n",
            "problems.\n",
            "Agentization\n",
            "To enhance the quality and reduce\n",
            "human intervention, ChatDev implements prompt\n",
            "engineering that only takes place at the start of\n",
            "each subtask round. As soon as the communica-\n",
            "tion phase begins, the instructor and the assistant\n",
            "will communicate with each other in an automated\n",
            "loop, continuing this exchange until the task con-\n",
            "cludes. However, simply exchanging responses\n",
            "cannot achieve effective multi-round task-oriented\n",
            "communication, since it inevitably faces significant\n",
            "challenges including role flipping, instruction re-\n",
            "peating, and fake replies. As a result, there is a\n",
            "failure to advance the progression of productive\n",
            "communications and hinders the achievement of\n",
            "meaningful solutions. ChatDev thus employs in-\n",
            "ception prompting mechanism (Li et al., 2023a)\n",
            "for initiating, sustaining, and concluding agents’\n",
            "communication to guarantee a robust and efficient\n",
            "workflow. This mechanism is composed of the in-\n",
            "structor system prompt PI and the assistant system\n",
            "prompt PA. The system prompts for both roles\n",
            "are mostly symmetrical, covering the overview and\n",
            "objectives of the current subtask, specialized roles,\n",
            "accessible external tools, communication protocols,\n",
            "termination conditions, and constraints or require-\n",
            "ments to avoid undesirable behaviors. Then, an\n",
            "instructor I and an assistant A are instantiated by\n",
            "hypnotizing LLMs via PI and PA:\n",
            "I = ρ(LLM, PI), A = ρ(LLM, PA)\n",
            "(2)\n",
            "where ρ is the role customization operation, imple-\n",
            "mented via system message assignment.\n",
            "Memory\n",
            "Note that the limited context length of\n",
            "common LLMs typically restricts the ability to\n",
            "maintain a complete communication history among\n",
            "all agents and phases. To tackle this issue, based\n",
            "on the nature of the chat chain, we accordingly seg-\n",
            "ment the agents’ context memories based on their\n",
            "sequential phases, resulting in two functionally dis-\n",
            "tinct types of memory: short-term memory and\n",
            "long-term memory. Short-term memory is utilized\n",
            "to sustain the continuity of the dialogue within a\n",
            "single phase, while long-term memory is leveraged\n",
            "to preserve contextual awareness across different\n",
            "phases.\n",
            "Formally, short-term memory records an agent’s\n",
            "current phase utterances, aiding context-aware\n",
            "decision-making. At the time t during phase Pi,\n",
            "we use Ii\n",
            "t to represent the instructor’s instruction\n",
            "and Ai\n",
            "t for the assistant’s response. The short-term\n",
            "memory M collects utterances up to time t as:\n",
            "Mi\n",
            "t = ⟨(Ii\n",
            "1, Ai\n",
            "1), (Ii\n",
            "2, Ai\n",
            "2), . . . , (Ii\n",
            "t, Ai\n",
            "t)⟩\n",
            "(3)\n",
            "In the next time step t + 1, the instructor utilizes\n",
            "the current memory to generate a new instruction\n",
            "Ii\n",
            "t+1, which is then conveyed to the assistant to pro-\n",
            "duce a new response Ai\n",
            "t+1. The short-term memory\n",
            "iteratively updates until the number of communica-\n",
            "tions reaches the upper limit |Mi|:\n",
            "Ii\n",
            "t+1 =I(Mi\n",
            "t), Ai\n",
            "t+1 = A(Mi\n",
            "t, Ii\n",
            "t+1)\n",
            "Mi\n",
            "t+1 = Mi\n",
            "t ∪(Ii\n",
            "t+1, Ai\n",
            "t+1)\n",
            "(4)\n",
            "To perceive dialogues through previous phases,\n",
            "the chat chain only transmits the solutions from pre-\n",
            "vious phases as long-term memories ˜\n",
            "M, integrat-\n",
            "ing them at the start of the next phase and enabling\n",
            "the cross-phase transmission of long dialogues:\n",
            "Ii+1\n",
            "1\n",
            "= ˜\n",
            "Mi ∪Pi+1\n",
            "I\n",
            ",\n",
            "˜\n",
            "Mi =\n",
            "i[\n",
            "j=1\n",
            "τ(Mj\n",
            "|Mj|) (5)\n",
            "where P symbolizes a predetermined prompt that\n",
            "appears exclusively at the start of each phase.\n",
            "By sharing only the solutions of each subtask\n",
            "rather than the entire communication history, Chat-\n",
            "Dev minimizes the risk of being overwhelmed by\n",
            "too much information, enhancing concentration on\n",
            "each task and encouraging more targeted coopera-\n",
            "tion, while simultaneously facilitating cross-phase\n",
            "context continuity.\n",
            "3.2\n",
            "Communicative Dehallucination\n",
            "LLM hallucinations manifest when models gen-\n",
            "erate outputs that are nonsensical, factually incor-\n",
            "rect, or inaccurate (Dhuliawala et al., 2023; Zhang\n",
            "\fet al., 2023b). This issue is particularly concern-\n",
            "ing in software development, where programming\n",
            "languages demand precise syntax—the absence of\n",
            "even a single line can lead to system failure. We\n",
            "have observed that LLMs often produce coding hal-\n",
            "lucinations, which encompass potential issues like\n",
            "incomplete implementations, unexecutable code,\n",
            "and inconsistencies that don’t meet requirements.\n",
            "Coding hallucinations frequently appear when the\n",
            "assistant struggles to precisely follow instructions,\n",
            "often due to the vagueness and generality of cer-\n",
            "tain instructions that require multiple adjustments,\n",
            "making it challenging for agents to achieve full\n",
            "compliance. Inspired by this, we introduce com-\n",
            "municative dehallucination, which encourages the\n",
            "assistant to actively seek more detailed suggestions\n",
            "from the instructor before delivering a formal re-\n",
            "sponse.\n",
            "Specifically, a vanilla communication pattern\n",
            "between the assistant and the instructor follows a\n",
            "straightforward instruction-response format:\n",
            "⟨I →A, A ; I⟩⟲\n",
            "(6)\n",
            "In contrast, our communicative dehallucination\n",
            "mechanism features a deliberate \"role reversal\",\n",
            "where the assistant takes on an instructor-like role,\n",
            "proactively seeking more specific information (e.g.,\n",
            "the precise name of an external dependency and\n",
            "its related class) before delivering a conclusive re-\n",
            "sponse. After the instructor provides a specific\n",
            "modification suggestion, the assistant proceeds to\n",
            "perform precise optimization:\n",
            "⟨I →A, ⟨A →I, I ; A⟩⟲, A ; I⟩⟲\n",
            "(7)\n",
            "Since this mechanism tackles one concrete issue at\n",
            "a time, it requires multiple rounds of communica-\n",
            "tion to optimize various potential problems. The\n",
            "communication pattern instructs agents on how to\n",
            "communicate, enabling finer-grained information\n",
            "exchange for effective solution optimization, which\n",
            "practically aids in reducing coding hallucinations.\n",
            "4\n",
            "Evaluation\n",
            "Baselines\n",
            "We chose some representative LLM-\n",
            "based software development methods as our base-\n",
            "lines. GPT-Engineer (Osika, 2023) is a fundamen-\n",
            "tal single-agent approach in LLM-driven software\n",
            "agents with a precise understanding of task require-\n",
            "ments and the application of one-step reasoning,\n",
            "which highlights its efficiency in generating de-\n",
            "tailed software solutions at the repository level.\n",
            "MetaGPT (Hong et al., 2023) is an advanced frame-\n",
            "work that allocates specific roles to various LLM-\n",
            "driven software agents and incorporates standard-\n",
            "ized operating procedures to enable multi-agent\n",
            "participation. In each step agents with specific roles\n",
            "generate solutions by adhering to static instructions\n",
            "predefined by human experts.\n",
            "Datasets\n",
            "Note that, as of now, there isn’t a pub-\n",
            "licly accessible dataset containing textual descrip-\n",
            "tions of software requirements in the context of\n",
            "agent-driven software development. To this end,\n",
            "we are actively working towards developing a com-\n",
            "prehensive dataset for software requirement de-\n",
            "scriptions, which we refer to as SRDD (Software\n",
            "Requirement Description Dataset). Drawing on\n",
            "previous work (Li et al., 2023a), we utilize existing\n",
            "software descriptions as initial examples, which\n",
            "are then further developed through a process that\n",
            "combines LLM-based automatic generation with\n",
            "post-processing refinement guided by humans. As\n",
            "a result, this dataset includes important software\n",
            "categories from popular platforms such as Ubuntu,\n",
            "Google Play, Microsoft Store, and Apple Store. It\n",
            "comprises 1,200 software task prompts that have\n",
            "been carefully categorized into 5 main areas: Edu-\n",
            "cation, Work, Life, Game, and Creation. All these\n",
            "areas are further divided into 40 subcategories, and\n",
            "each subcategory contains 30 unique task prompts.\n",
            "Metrics\n",
            "Evaluating software is also a challenging\n",
            "task, especially when trying to assess it on a holistic\n",
            "level. Under the current limitation of scarce bench-\n",
            "mark resources, traditional function-oriented code\n",
            "generation metrics (e.g., pass@k), cannot seam-\n",
            "lessly transfer to a comprehensive evaluation of\n",
            "entire software systems. The main reason for this\n",
            "is that it is often impractical to develop manual or\n",
            "automated test cases for various types of software,\n",
            "especially those involving complex interfaces, fre-\n",
            "quent user interactions, or non-deterministic feed-\n",
            "back. As an initial strategy, we apply three funda-\n",
            "mental and objective dimensions that reflect differ-\n",
            "ent aspects of coding hallucinations to evaluate the\n",
            "agent-generated software, and then integrate them\n",
            "to facilitate a more holistic evaluation:\n",
            "• Completeness measures the software’s ability to\n",
            "fulfill code completion in software development,\n",
            "quantified as the percentage of software with-\n",
            "out any \"placeholder\" code snippets. A higher\n",
            "score indicates a higher probability of automated\n",
            "completion.\n",
            "\fMethod\n",
            "Paradigm\n",
            "Completeness\n",
            "Executability\n",
            "Consistency\n",
            "Quality\n",
            "GPT-Engineer\n",
            "0.5022†\n",
            "0.3583†\n",
            "0.7887†\n",
            "0.1419†\n",
            "MetaGPT\n",
            "0.4834†\n",
            "0.4145†\n",
            "0.7601†\n",
            "0.1523†\n",
            "ChatDev\n",
            "0.5600\n",
            "0.8800\n",
            "0.8021\n",
            "0.3953\n",
            "Table 1: Overall performance of the LLM-powered software development methods, encompassing both single-agent\n",
            "(\n",
            ") and multi-agent (\n",
            ") paradigms. Performance metrics are averaged for all tasks. The top scores are in bold,\n",
            "with second-highest underlined. † indicates significant statistical differences (p≤0.05) between a baseline and ours.\n",
            "Method\n",
            "Evaluator\n",
            "Baseline Wins\n",
            "ChatDev Wins\n",
            "Draw\n",
            "GPT-Engineer\n",
            "GPT-4\n",
            "22.50%\n",
            "77.08%\n",
            "00.42%\n",
            "Human\n",
            "09.18%\n",
            "90.16%\n",
            "00.66%\n",
            "MetaGPT\n",
            "GPT-4\n",
            "37.50%\n",
            "57.08%\n",
            "05.42%\n",
            "Human\n",
            "07.92%\n",
            "88.00%\n",
            "04.08%\n",
            "Table 2: Pairwise evaluation results.\n",
            "• Executability assesses the software’s ability to\n",
            "run correctly within a compilation environment,\n",
            "quantified as the percentage of software that com-\n",
            "piles successfully and can run directly. A higher\n",
            "score indicates a higher probability of successful\n",
            "execution.\n",
            "• Consistency measures how closely the generated\n",
            "software code aligns with the original require-\n",
            "ment description, quantified as the cosine dis-\n",
            "tance between the semantic embeddings of the\n",
            "textual requirements and the generated software\n",
            "code1. A higher score indicates a greater degree\n",
            "of consistency with the requirements.\n",
            "• Quality is a comprehensive metric that integrates\n",
            "various factors to assess the overall quality of\n",
            "software, quantified by multiplying2 complete-\n",
            "ness, executability, and consistency. A higher\n",
            "quality score suggests a higher overall satisfac-\n",
            "tion with the software generated, implying a\n",
            "lower need for further manual intervention.\n",
            "Implementation Details\n",
            "We divided software\n",
            "development into 5 subtasks within 3 phases, as-\n",
            "signing specific roles like CEO, CTO, programmer,\n",
            "reviewer, and tester. A subtask would terminate\n",
            "and get a conclusion either after two unchanged\n",
            "code modifications or after 10 rounds of commu-\n",
            "nication. During the code completion, review, and\n",
            "testing, a communicative dehallucination is acti-\n",
            "vated. For ease of identifying solutions, the assis-\n",
            "tant begins responses with \"<SOLUTION>\" when\n",
            "1Comments should be excluded from the code to avoid\n",
            "potential information leakage during evaluations.\n",
            "2One can also choose to average the sub-metrics, which\n",
            "yields similar trends.\n",
            "Method\n",
            "Duration (s)\n",
            "#Tokens\n",
            "#Files\n",
            "#Lines\n",
            "GPT-Engineer\n",
            "15.6000\n",
            "7,182.5333\n",
            "3.9475\n",
            "70.2041\n",
            "MetaGPT\n",
            "154.0000\n",
            "29,278.6510\n",
            "4.4233\n",
            "153.3000\n",
            "ChatDev\n",
            "148.2148\n",
            "22,949.4450\n",
            "4.3900\n",
            "144.3450\n",
            "Table 3: Software statistics include Duration (time con-\n",
            "sumed), #Tokens (number of tokens used), #Files (num-\n",
            "ber of code files generated), and #Lines (total lines of\n",
            "code across all files) in the software generation process.\n",
            "a consensus is reached. We used ChatGPT-3.5 with\n",
            "a temperature of 0.2 and integrated Python-3.11.4\n",
            "for feedback. All baselines in the evaluation share\n",
            "the same hyperparameters and settings for fairness.\n",
            "4.1\n",
            "Overall Performance\n",
            "As illustrated in Table 1, ChatDev outperforms\n",
            "all baseline methods across all metrics, showing\n",
            "a considerable margin of improvement. Firstly,\n",
            "the improvement of ChatDev and MetaGPT over\n",
            "GPT-Engineer demonstrates that complex tasks are\n",
            "difficult to solve in a single-step solution. There-\n",
            "fore, explicitly decomposing the difficult problem\n",
            "into several smaller, more manageable subtasks en-\n",
            "hances the effectiveness of task completion. Addi-\n",
            "tionally, in comparison to MetaGPT, ChatDev sig-\n",
            "nificantly raises the Quality from 0.1523 to 0.3953.\n",
            "This advancement is largely attributed to the agents\n",
            "employing a cooperative communication method,\n",
            "which involves autonomously proposing and con-\n",
            "tinuously refining source code through a blend of\n",
            "natural and programming languages, as opposed\n",
            "to merely delivering responses based on human-\n",
            "predefined instructions. The communicative agents\n",
            "guide each subtask towards integrated and auto-\n",
            "mated solutions, efficiently overcoming the restric-\n",
            "tions typically linked to manually established op-\n",
            "timization rules, and offering a more versatile and\n",
            "adaptable framework for problem-solving.\n",
            "To further understand user preferences in practi-\n",
            "cal settings, we use the setting adopted by Li et al.\n",
            "(2023a), where agent-generated solutions are com-\n",
            "\fVariant\n",
            "Completeness\n",
            "Executability\n",
            "Consistency\n",
            "Quality\n",
            "ChatDev\n",
            "0.5600\n",
            "0.8800\n",
            "0.8021\n",
            "0.3953\n",
            "≤Coding\n",
            "0.4100\n",
            "0.7700\n",
            "0.7958\n",
            "0.2512\n",
            "≤Complete\n",
            "0.6250\n",
            "0.7400\n",
            "0.7978\n",
            "0.3690\n",
            "≤Review\n",
            "0.5750\n",
            "0.8100\n",
            "0.7980\n",
            "0.3717\n",
            "≤Testing\n",
            "0.5600\n",
            "0.8800\n",
            "0.8021\n",
            "0.3953\n",
            "⧹CDH\n",
            "0.4700\n",
            "0.8400\n",
            "0.7983\n",
            "0.3094\n",
            "⧹Roles\n",
            "0.5400\n",
            "0.5800\n",
            "0.7385\n",
            "0.2212\n",
            "Table 4: Ablation study on main components or mech-\n",
            "anisms. ≤x denotes halting the chat chain after the\n",
            "completion of the x phrase, and ⧹denotes the removing\n",
            "operation. CDH denotes the communicative dehalluci-\n",
            "nation mechanism.\n",
            "pared in pairs by both human participants and the\n",
            "prevalent GPT-4 model to identify the preferred\n",
            "one.3 Table 2 shows ChatDev consistently outper-\n",
            "forming other baselines, with higher average win\n",
            "rates in both GPT-4 and human evaluations.\n",
            "Furthermore, the software statistics presented\n",
            "in Table 3 indicates that the multi-agent paradigm,\n",
            "despite being slower and consuming more tokens\n",
            "than the single-agent method, yields a greater num-\n",
            "ber of code files and a larger codebase, which may\n",
            "enhance the software’s functionality and integrity.\n",
            "Analyzing the dialogues of agents suggests that\n",
            "the multi-agent communication method often leads\n",
            "agents to autonomously offer functional enhance-\n",
            "ments (e.g., GUI creation or increasing game diffi-\n",
            "culty), thereby potentially resulting in the incorpo-\n",
            "ration of beneficial features that were not explicitly\n",
            "specified in requirements. Taking all these factors\n",
            "together, we posit that the fundamental character-\n",
            "istics of multi-agent software development take\n",
            "on greater significance, surpassing short-term con-\n",
            "cerns like time and economic costs in the current\n",
            "landscape.\n",
            "4.2\n",
            "Ablation Study\n",
            "This section examines key components or mech-\n",
            "anisms within our multi-agent cooperation frame-\n",
            "work by removing particular phases in the chat\n",
            "chain, communicative dehallucination, or the roles\n",
            "assigned to all agents in their system prompts. Fig-\n",
            "ure 4 shows that the code complete phase enhances\n",
            "Completeness, with testing critical for Executabil-\n",
            "ity. Quality steadily rises with each step, suggesting\n",
            "that software development optimization is progres-\n",
            "sively attained through multi-phase communica-\n",
            "3For fairness, GPT-4’s evaluation mitigated possible po-\n",
            "sitional bias (Wang et al., 2023c), and human experts inde-\n",
            "pendently assessed the task solutions, randomized to prevent\n",
            "order bias.\n",
            "Natural-Language\n",
            "Programming-Language\n",
            "Target User\n",
            "UI & UX\n",
            "Data Management\n",
            "Customization\n",
            "Performance\n",
            "Integration\n",
            "Real-Time Update\n",
            "Recommendation\n",
            "Platform\n",
            "Collaboration\n",
            "Security & Privacy\n",
            "Scalability & Maintenance\n",
            "Coding\n",
            "Code Complete\n",
            "Code Review\n",
            "System Testing\n",
            "57.20%\n",
            "42.80%\n",
            "10.19%\n",
            "61.09%\n",
            "10.19%\n",
            "18.53%\n",
            "21.44%\n",
            "20.55%\n",
            "19.23%\n",
            "7.78%\n",
            "6.93%\n",
            "5.92%\n",
            "5.41%\n",
            "3.46%\n",
            "3.15%\n",
            "2.51%\n",
            "2.24%\n",
            "1.39%\n",
            "Figure 3: The utterance distribution of agent communi-\n",
            "cations throughout the entire development process.\n",
            "tions among intelligent agents. Meanwhile, elim-\n",
            "inating communicative dehallucination results in\n",
            "a decrease across all metrics, indicating its effec-\n",
            "tiveness in addressing coding hallucinations. Most\n",
            "interestingly, the most substantial impact on per-\n",
            "formance occurs when the roles of all agents are\n",
            "removed from their system prompts. Detailed dia-\n",
            "logue analysis shows that assigning a \"prefer GUI\n",
            "design\" role to a programmer results in generated\n",
            "source code with relevant GUI implementations; in\n",
            "the absence of such role indications, it defaults to\n",
            "implement unfriend command-line-only programs\n",
            "only. Likewise, assigning roles such as a \"careful\n",
            "reviewer for bug detection\" enhances the chances\n",
            "of discovering code vulnerabilities; without such\n",
            "roles, feedback tends to be high-level, leading to\n",
            "limited adjustments by the programmer. This find-\n",
            "ing underscores the importance of assigning roles\n",
            "in eliciting responses from LLMs, underscoring the\n",
            "significant influence of multi-agent cooperation on\n",
            "software quality.\n",
            "4.3\n",
            "Communication Analysis\n",
            "Our agent-driven software development paradigm\n",
            "promotes cooperative agents through effective com-\n",
            "munication for automated solution optimization.\n",
            "Phases in the chat chain have varying levels of en-\n",
            "gagement in natural and programming languages.\n",
            "\fInput\n",
            "Output\n",
            "Method Not Implemented\n",
            "Modules Not Imported\n",
            "Missing Code Segments\n",
            "Not Conﬁgure Layout\n",
            "Missing Comments\n",
            "Class Deﬁned Twice\n",
            "Methods Not Called\n",
            "Missing Exception Handling\n",
            "Missing Initialization\n",
            "Missing Files\n",
            "Not Correctly Processing Data\n",
            "Class Not Used\n",
            "Calling without Correct Arguments\n",
            "Not Handle Cases\n",
            "Missing Imports\n",
            "No Further Suggestions\n",
            "Method Not Implemented\n",
            "Modules Not Imported\n",
            "Missing Code Segments\n",
            "Not Conﬁgure Layout\n",
            "Not Correctly Processing Data\n",
            "Missing Comments\n",
            "Missing Exception Handling\n",
            "Missing Files\n",
            "Missing Initialization\n",
            "Missing Imports\n",
            "Methods Not Called\n",
            "No Further Suggestions\n",
            "Calling without Correct Arguments\n",
            "Class Not Used\n",
            "Class Deﬁned Twice\n",
            "Not Handle Cases\n",
            "Method Not Implemented\n",
            "Modules Not Imported\n",
            "Missing Code Segments\n",
            "Missing Comments\n",
            "Not Conﬁgure Layout\n",
            "No Further Suggestions\n",
            "Missing Files\n",
            "Methods Not Called\n",
            "Not Correctly Processing Data\n",
            "Missing Exception Handling\n",
            "Missing Initialization\n",
            "Class Not Used\n",
            "Missing Imports\n",
            "Calling without Correct Arguments\n",
            "Not Handle Cases\n",
            "Class Deﬁned Twice\n",
            "Figure 4: The chart demonstrates the distribution of suggestions made by a reviewer agent during a multi-round\n",
            "reviewing process, where each sector in the chart represents a different category of suggestion.\n",
            "We now analyze the content of their communica-\n",
            "tions to understand linguistic effects.\n",
            "Figure 3 depicts a communication breakdown,\n",
            "with natural language at 57.20%. In the natural-\n",
            "language phase (i.e., design), natural language com-\n",
            "munication plays a crucial role in the thorough\n",
            "design of the system, with agents autonomously\n",
            "discussing and designing aspects like target user,\n",
            "data management, and user interface. Post-design\n",
            "phases show a balanced mix of coding, code com-\n",
            "pletion, and testing activities, with most communi-\n",
            "cation occurring during code reviews. This trend is\n",
            "due to agents’ self-reviews and code fixes consis-\n",
            "tently propelling software development; otherwise,\n",
            "progress halts when successive updates don’t show\n",
            "significant changes, leading to a natural decrease\n",
            "in code review communications.\n",
            "We explore the properties of static debugging\n",
            "dynamics in code reviews resulting from commu-\n",
            "nication between reviewers and programmers, as\n",
            "depicted in Figure 4. The data uncovers that dur-\n",
            "ing the review phase, reviewers may spot different\n",
            "issues through language interactions. The program-\n",
            "mer’s intervention can transform certain issues into\n",
            "different ones or a state where no further sugges-\n",
            "tions are needed; the increasing proportion of the\n",
            "latter indicates successful software optimization.\n",
            "Particularly, the \"Method Not Implemented\" is-\n",
            "sue is most common in communication between\n",
            "reviewers and programmers during code reviews,\n",
            "accounting for 34.85% of discussions. This prob-\n",
            "lem usually arises from unclear text requirements\n",
            "and the use of \"placeholder\" tags in Python code,\n",
            "necessitating additional manual adjustments. Fur-\n",
            "thermore, the \"Module Not Imported\" issue often\n",
            "arises due to code generation omitting crucial de-\n",
            "tails. Apart from common problems, reviewers\n",
            "often focus on enhancing code robustness by iden-\n",
            "tifying rare exceptions, unused classes, or potential\n",
            "infinite loops.\n",
            "Likewise, we analyze the tester-programmer\n",
            "communication during the testing phase, illus-\n",
            "trating the dynamic debugging dynamics in their\n",
            "multi-turn interactions with compiler feedback,\n",
            "as depicted in Figure 5.\n",
            "The likelihood of\n",
            "successful compilation at each step is generally\n",
            "higher than encountering errors, with most er-\n",
            "rors persisting and a lower probability of trans-\n",
            "forming into different errors.\n",
            "The most fre-\n",
            "quent error is \"ModuleNotFound\" (45.76%), fol-\n",
            "lowed by \"NameError\" and \"ImportError\" (each\n",
            "at 15.25%). The observation highlights the model’s\n",
            "tendency to overlook basic elements like an \"im-\n",
            "port\" statement, underscoring its difficulty in man-\n",
            "aging intricate details during code generation. Be-\n",
            "sides, the tester also detects rarer errors like im-\n",
            "properly initialized GUIs, incorrect method calls,\n",
            "missing file dependencies, and unused modules.\n",
            "The communicative dehallucination mechanism ef-\n",
            "fectively resolves certain errors, frequently result-\n",
            "ing in \"compilation success\" after code changes.\n",
            "There’s a significantly low chance of returning to\n",
            "an error state from a successful compilation. Over\n",
            "time, the multi-turn communication process statisti-\n",
            "\fSuccess\n",
            "AttributeError\n",
            "DatabaseError\n",
            "EOFError\n",
            "FileNotFoundError\n",
            "ImportError\n",
            "IndentationError\n",
            "JSONDecodeError\n",
            "KeyError\n",
            "ModuleNotFoundError\n",
            "NameError\n",
            "OperationalError\n",
            "RuntimeError\n",
            "SSLError\n",
            "SyntaxError\n",
            "TclError\n",
            "TypeError\n",
            "ValueError\n",
            "Others\n",
            "Success\n",
            "Success\n",
            "Input\n",
            "Output\n",
            "Success\n",
            "AttributeError\n",
            "DatabaseError\n",
            "EOFError\n",
            "FileNotFoundError\n",
            "ImportError\n",
            "IndentationError\n",
            "JSONDecodeError\n",
            "KeyError\n",
            "ModuleNotFoundError\n",
            "NameError\n",
            "OperationalError\n",
            "RuntimeError\n",
            "SSLError\n",
            "SyntaxError\n",
            "TclError\n",
            "TypeError\n",
            "ValueError\n",
            "Others\n",
            "AttributeError\n",
            "DatabaseError\n",
            "EOFError\n",
            "FileNotFoundError\n",
            "ImportError\n",
            "IndentationError\n",
            "JSONDecodeError\n",
            "KeyError\n",
            "ModuleNotFoundError\n",
            "NameError\n",
            "OperationalError\n",
            "RuntimeError\n",
            "SSLError\n",
            "SyntaxError\n",
            "TclError\n",
            "TypeError\n",
            "ValueError\n",
            "Others\n",
            "AttributeError\n",
            "DatabaseError\n",
            "FileNotFoundError\n",
            "ImportError\n",
            "IndentationError\n",
            "JSONDecodeError\n",
            "ModuleNotFoundError\n",
            "NameError\n",
            "OperationalError\n",
            "RuntimeError\n",
            "SyntaxError\n",
            "TclError\n",
            "TypeError\n",
            "ValueError\n",
            "Others\n",
            "Figure 5: The diagram illustrates the progression of iterations in a multi-round testing process, where each colored\n",
            "column represents a dialogue round, showcasing the evolution of the solution through successive stages of testing.\n",
            "cally shows a consistent decrease in errors, steadily\n",
            "moving towards successful software execution.\n",
            "5\n",
            "Conclusion\n",
            "We have introduced ChatDev, an innovative multi-\n",
            "agent collaboration framework for software devel-\n",
            "opment that utilizes multiple LLM-powered agents\n",
            "to integrate fragmented phases of the waterfall\n",
            "model into a cohesive communication system. It\n",
            "features chat chain organizing communication tar-\n",
            "gets and dehallucination for resolving coding hal-\n",
            "lucinations. The results demonstrate its superiority\n",
            "and highlight the benefits of multi-turn communi-\n",
            "cations in software optimization. We aim for the\n",
            "insights to advance LLM agents towards increased\n",
            "autonomy and illuminate the profound effects of\n",
            "\"language\" and its empowering role across an even\n",
            "broader spectrum of applications.\n",
            "6\n",
            "Limitations\n",
            "Our study explores the potential of cooperative\n",
            "autonomous agents in software development, but\n",
            "certain limitations and risks must be considered by\n",
            "researchers and practitioners. Firstly, the capabili-\n",
            "ties of autonomous agents in software production\n",
            "might be overestimated. While they enhance de-\n",
            "velopment quality, agents often implement simple\n",
            "logic, resulting in low information density. With-\n",
            "out clear, detailed requirements, agents struggle to\n",
            "grasp task ideas. For instance, vague guidelines in\n",
            "developing a Snake game lead to basic representa-\n",
            "tions; in information management systems, agents\n",
            "might retrieve static key-value placeholders instead\n",
            "of external databases. Therefore, it is crucial to\n",
            "clearly define detailed software requirements. Cur-\n",
            "rently, these technologies are more suitable for pro-\n",
            "totype systems rather than complex real-world ap-\n",
            "plications. Secondly, unlike traditional function-\n",
            "level code generation, automating the evaluation of\n",
            "general-purpose software is highly complex. While\n",
            "some efforts have focused on Human Revision\n",
            "Cost (Hong et al., 2023), manual verification for\n",
            "large datasets is impractical. Our paper emphasizes\n",
            "completeness, executability, consistency, and over-\n",
            "all quality, but future research should consider ad-\n",
            "ditional factors such as functionalities, robustness,\n",
            "safety, and user-friendliness. Thirdly, compared to\n",
            "single-agent approaches, multiple agents require\n",
            "more tokens and time, increasing computational de-\n",
            "mands and environmental impact. Future research\n",
            "should aim to enhance agent capabilities with fewer\n",
            "interactions. Despite these limitations, we believe\n",
            "that engaging a broader, technically proficient au-\n",
            "dience can unlock additional potential directions in\n",
            "LLM-powered multi-agent collaboration.\n",
            "Acknowledgments\n",
            "The work was supported by the National Key R&D\n",
            "Program of China (No.2022ZD0116312), the Post-\n",
            "doctoral Fellowship Program of CPSF under Grant\n",
            "Number GZB20230348, and Tencent Rhino-Bird\n",
            "Focused Research Program.\n",
            "\fReferences\n",
            "Silvia T Acuna, Natalia Juristo, and Ana M Moreno.\n",
            "2006. Emphasizing Human Capabilities in Software\n",
            "Development. In IEEE Software, volume 23, pages\n",
            "94–101.\n",
            "Mansi Agnihotri and Anuradha Chug. 2020. A Sys-\n",
            "tematic Literature Survey of Software Metrics, Code\n",
            "Smells and Refactoring Techniques. In booktitle of\n",
            "Information Processing Systems, volume 16, pages\n",
            "915–934.\n",
            "Rajiv D Banker, Gordon B Davis, and Sandra A Slaugh-\n",
            "ter. 1998. Software Development Practices, Software\n",
            "Complexity, and Software Maintenance Performance:\n",
            "A Field Study. In Management science, volume 44,\n",
            "pages 433–450.\n",
            "Victor R Basili. 1989.\n",
            "Software Development: A\n",
            "Paradigm for The Future. In Proceedings of the An-\n",
            "nual International Computer Software and Applica-\n",
            "tions Conference, pages 471–485. IEEE.\n",
            "Thorsten Brants, Ashok C Popat, Peng Xu, Franz J Och,\n",
            "and Jeffrey Dean. 2007. Large Language Models in\n",
            "Machine Translation. In Proceedings of the 2007\n",
            "Joint Conference on Empirical Methods in Natural\n",
            "Language Processing and Computational Natural\n",
            "Language Learning (EMNLP-CoNLL), pages 858–\n",
            "867.\n",
            "Tom Brown, Benjamin Mann, Nick Ryder, Melanie\n",
            "Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\n",
            "Neelakantan, Pranav Shyam, Girish Sastry, Amanda\n",
            "Askell, Sandhini Agarwal, Ariel Herbert-Voss,\n",
            "Gretchen Krueger, Tom Henighan, Rewon Child,\n",
            "Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens\n",
            "Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-\n",
            "teusz Litwin, Scott Gray, Benjamin Chess, Jack\n",
            "Clark, Christopher Berner, Sam McCandlish, Alec\n",
            "Radford, Ilya Sutskever, and Dario Amodei. 2020.\n",
            "Language Models are Few-Shot Learners. In Ad-\n",
            "vances in Neural Information Processing Systems\n",
            "(NeurIPS), volume 33, pages 1877–1901.\n",
            "Sébastien Bubeck, Varun Chandrasekaran, Ronen El-\n",
            "dan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Pe-\n",
            "ter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg,\n",
            "Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro,\n",
            "and Yi Zhang. 2023. Sparks of artificial general in-\n",
            "telligence: Early experiments with gpt-4. In arXiv\n",
            "preprint arXiv:2303.12712.\n",
            "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen,\n",
            "and Denny Zhou. 2023. Large Language Models as\n",
            "Tool Makers. In arXiv preprint arXiv:2305.17126.\n",
            "Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu,\n",
            "Wei Xue, Shanghang Zhang, Jie Fu, and Zhiyuan\n",
            "Liu. 2023. ChatEval: Towards Better LLM-based\n",
            "Evaluators through Multi-Agent Debate. In arXiv\n",
            "preprint arXiv:2308.07201.\n",
            "Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li,\n",
            "and Haoyang Zhang. 2023a. GameGPT: Multi-agent\n",
            "Collaborative Framework for Game Development. In\n",
            "arXiv preprint arXiv:2310.08067.\n",
            "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan,\n",
            "Henrique Ponde de Oliveira Pinto, Jared Kaplan,\n",
            "Harri Edwards, Yuri Burda, Nicholas Joseph, Greg\n",
            "Brockman, et al. 2021.\n",
            "Evaluating Large Lan-\n",
            "guage Models Trained on Code. In arXiv preprint\n",
            "arXiv:2107.03374.\n",
            "Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang,\n",
            "Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin,\n",
            "Yaxi Lu, Ruobing Xie, et al. 2023b. AgentVerse:\n",
            "Facilitating Multi-agent Collaboration and Explor-\n",
            "ing Emergent Behaviors in Agents. In International\n",
            "Conference on Learning Representations (ICLR).\n",
            "Roi Cohen, May Hamri, Mor Geva, and Amir Glober-\n",
            "son. 2023.\n",
            "LM vs LM: Detecting Factual Er-\n",
            "rors via Cross Examination.\n",
            "In ArXiv, volume\n",
            "abs/2305.13281.\n",
            "Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu,\n",
            "Roberta Raileanu, Xian Li, Asli Celikyilmaz, and\n",
            "Jason Weston. 2023. Chain-of-Verification Reduces\n",
            "Hallucination in Large Language Models. In arXiv\n",
            "preprint arXiv:2309.11495.\n",
            "Shiying Ding, Xinyi Chen, Yan Fang, Wenrui Liu, Yiwu\n",
            "Qiu, and Chunlei Chai. 2023. DesignGPT: Multi-\n",
            "Agent Collaboration in Design. In arXiv preprint\n",
            "arXiv:2311.11591.\n",
            "Michael D. Ernst. 2017. Natural Language is a Pro-\n",
            "gramming Language: Applying Natural Language\n",
            "Processing to Software Development. In Advances\n",
            "in Programming Languages (SNAPL), volume 71,\n",
            "pages 4:1–4:14.\n",
            "Saad Ezzini, Sallam Abualhaija, Chetan Arora, and\n",
            "Mehrdad Sabetzadeh. 2022. Automated Handling\n",
            "of Anaphoric Ambiguity in Requirements: A Multi-\n",
            "solution Study. In International Conference on Soft-\n",
            "ware Engineering (ICSE), pages 187–199.\n",
            "Robert France and Bernhard Rumpe. 2007. Model-\n",
            "driven Development of Complex Software: A Re-\n",
            "search Roadmap. In Future of Software Engineering\n",
            "(FOSE), pages 37–54.\n",
            "Peter Freeman, Donald J. Bagert, Hossein Saiedian,\n",
            "Mary Shaw, Robert Dupuis, and J. Barrie Thompson.\n",
            "2001. Software Engineering Body of Knowledge\n",
            "(SWEBOK). In Proceedings of the International\n",
            "Conference on Software Engineering (ICSE), pages\n",
            "693–696.\n",
            "Sa Gao, Chunyang Chen, Zhenchang Xing, Yukun Ma,\n",
            "Wen Song, and Shang-Wei Lin. 2019.\n",
            "A Neural\n",
            "Model for Method Name Generation from Functional\n",
            "Description. In 26th IEEE International Conference\n",
            "on Software Analysis, Evolution and Reengineering\n",
            "(SANER), pages 411–421.\n",
            "\fSirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu\n",
            "Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang,\n",
            "Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang\n",
            "Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu,\n",
            "and Jürgen Schmidhuber. 2023. MetaGPT: Meta Pro-\n",
            "gramming for A Multi-Agent Collaborative Frame-\n",
            "work. In International Conference on Learning Rep-\n",
            "resentations (ICLR).\n",
            "Wenyue Hua, Lizhou Fan, Lingyao Li, Kai Mei,\n",
            "Jianchao Ji, Yingqiang Ge, Libby Hemphill, and\n",
            "Yongfeng Zhang. 2023.\n",
            "War and Peace (WarA-\n",
            "gent): Large Language Model-based Multi-Agent\n",
            "Simulation of World Wars.\n",
            "In arXiv preprint\n",
            "arXiv:2311.17227.\n",
            "Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\n",
            "Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea\n",
            "Madotto, and Pascale Fung. 2023. Survey of Hal-\n",
            "lucination in Natural Language Generation. In ACM\n",
            "Computing Surveys, volume 55, pages 1–38.\n",
            "Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B.\n",
            "Brown, Benjamin Chess, Rewon Child, Scott Gray,\n",
            "Alec Radford, Jeffrey Wu, and Dario Amodei. 2020.\n",
            "Scaling Laws for Neural Language Models. In arXiv\n",
            "preprint arXiv:2001.08361.\n",
            "Guohao Li, Hasan Abed Al Kader Hammoud, Hani\n",
            "Itani, Dmitrii Khizbullin, and Bernard Ghanem.\n",
            "2023a. CAMEL: Communicative Agents for \"Mind\"\n",
            "Exploration of Large Scale Language Model Society.\n",
            "In Thirty-seventh Conference on Neural Information\n",
            "Processing Systems (NeurIPS).\n",
            "Yuan Li, Yixuan Zhang, and Lichao Sun. 2023b.\n",
            "MetaAgents:\n",
            "Simulating Interactions of Human\n",
            "Behaviors for LLM-based Task-oriented Coordina-\n",
            "tion via Collaborative Generative Agents. In arXiv\n",
            "preprint arXiv:2310.06500.\n",
            "Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue,\n",
            "Shelby Heinecke, Rithesh Murthy, Yihao Feng,\n",
            "Zeyuan Chen, Juan Carlos Niebles, Devansh Arpit,\n",
            "Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, and\n",
            "Silvio Savarese. 2023. BOLAA: Benchmarking and\n",
            "Orchestrating LLM-augmented Autonomous Agents.\n",
            "In arXiv preprint arXiv:2308.05960.\n",
            "Kaixin Ma, Hongming Zhang, Hongwei Wang, Xiao-\n",
            "man Pan, and Dong Yu. 2023. LASER: LLM Agent\n",
            "with State-Space Exploration for Web Navigation. In\n",
            "arXiv preprint arXiv:2309.08172.\n",
            "Cuauhtémoc López Martín and Alain Abran. 2015. Neu-\n",
            "ral networks for predicting the duration of new soft-\n",
            "ware projects. In J. Syst. Softw., volume 101, pages\n",
            "127–135.\n",
            "Nadia Nahar, Shurui Zhou, Grace A. Lewis, and\n",
            "Christian Kästner. 2022. Collaboration Challenges\n",
            "in Building ML-Enabled Systems:\n",
            "Communica-\n",
            "tion, Documentation, Engineering, and Process. In\n",
            "IEEE/ACM International Conference on Software\n",
            "Engineering (ICSE), pages 413–425.\n",
            "Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan\n",
            "Wang, Yingbo Zhou, Silvio Savarese, and Caiming\n",
            "Xiong. 2023. CodeGen: An Open Large Language\n",
            "Model for Code with Multi-Turn Program Synthe-\n",
            "sis. In The International Conference on Learning\n",
            "Representations (ICLR).\n",
            "Anton\n",
            "Osika.\n",
            "2023.\n",
            "GPT-Engineer.\n",
            "In\n",
            "https://github.com/AntonOsika/gpt-engineer.\n",
            "Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida,\n",
            "Carroll L. Wainwright, Pamela Mishkin, Chong\n",
            "Zhang, Sandhini Agarwal, Katarina Slama, Alex\n",
            "Ray, John Schulman, Jacob Hilton, Fraser Kelton,\n",
            "Luke Miller, Maddie Simens, Amanda Askell, Pe-\n",
            "ter Welinder, Paul Christiano, Jan Leike, and Ryan\n",
            "Lowe. 2022. Training Language Models to Follow\n",
            "Instructions with Human Feedback. In arXiv preprint\n",
            "arXiv:2203.02155.\n",
            "Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Mered-\n",
            "ith Ringel Morris, Percy Liang, and Michael S. Bern-\n",
            "stein. 2023. Generative Agents: Interactive Simu-\n",
            "lacra of Human Behavior. In Proceedings of the 36th\n",
            "Annual ACM Symposium on User Interface Software\n",
            "and Technology (UIST).\n",
            "Florian Pudlitz, Florian Brokhausen, and Andreas Vo-\n",
            "gelsang. 2019. Extraction of System States from\n",
            "Natural Language Requirements. In IEEE Interna-\n",
            "tional Requirements Engineering Conference (RE),\n",
            "pages 211–222.\n",
            "Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan\n",
            "Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang,\n",
            "Bill Qian, et al. 2023a. ToolLLM: Facilitating Large\n",
            "Language Models to Master 16000+ Real-World\n",
            "APIs. In arXiv preprint arXiv:2307.16789.\n",
            "Zhen Qin, Rolf Jagerman, Kai Hui, Honglei Zhuang,\n",
            "Junru Wu, Jiaming Shen, Tianqi Liu, Jialu Liu, Don-\n",
            "ald Metzler, Xuanhui Wang, and Michael Bendersky.\n",
            "2023b. Large Language Models are Effective Text\n",
            "Rankers with Pairwise Ranking Prompting. In arXiv\n",
            "preprint arXiv:2306.17563.\n",
            "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,\n",
            "Dario Amodei, Ilya Sutskever, et al. Language Mod-\n",
            "els are Unsupervised Multitask Learners. In OpenAI\n",
            "Blog, volume 1, page 9.\n",
            "Toran Bruce Richards. 2023.\n",
            "AutoGPT.\n",
            "In\n",
            "https://github.com/Significant-Gravitas/AutoGPT.\n",
            "Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu,\n",
            "Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu\n",
            "Mao, Ziyue Li, Xingyu Zeng, and Rui Zhao. 2023.\n",
            "TPTU: Large Language Model-based AI Agents for\n",
            "Task Planning and Tool Usage. In arXiv preprint\n",
            "arXiv:2308.03427.\n",
            "Steve Sawyer and Patricia J. Guinan. 1998. Software\n",
            "development: Processes and Performance. In IBM\n",
            "Systems Journal, volume 37, pages 552–569.\n",
            "\fTimo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta\n",
            "Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola\n",
            "Cancedda, and Thomas Scialom. 2023. ToolFormer:\n",
            "Language Models Can Teach Themselves to Use\n",
            "Tools. In arXiv preprint arXiv:2302.04761.\n",
            "Murray Shanahan, Kyle McDonell, and Laria Reynolds.\n",
            "2023. Role Play with Large Language Models. In\n",
            "Nature, volume 623, pages 493–498.\n",
            "Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan,\n",
            "and Thomas L. Griffiths. 2023. Cognitive Archi-\n",
            "tectures for Language Agents.\n",
            "In arXiv preprint\n",
            "arXiv:2309.02427.\n",
            "Hannes Thaller, Lukas Linsbauer, and Alexander Egyed.\n",
            "2019. Feature Maps: A Comprehensible Software\n",
            "Representation for Design Pattern Detection.\n",
            "In\n",
            "IEEE International Conference on Software Anal-\n",
            "ysis, Evolution and Reengineering (SANER), pages\n",
            "207–217.\n",
            "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\n",
            "Martinet, Marie-Anne Lachaux, Timothée Lacroix,\n",
            "Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal\n",
            "Azhar, et al. 2023.\n",
            "LLaMA: Open and Efficient\n",
            "Foundation Language Models.\n",
            "In arXiv preprint\n",
            "arXiv:2302.13971.\n",
            "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\n",
            "Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz\n",
            "Kaiser, and Illia Polosukhin. 2017. Attention is All\n",
            "You Need. In Advances in Neural Information Pro-\n",
            "cessing Systems (NeurIPS), volume 30.\n",
            "Chengcheng Wan, Shicheng Liu, Sophie Xie, Yifan\n",
            "Liu, Henry Hoffmann, Michael Maire, and Shan Lu.\n",
            "2022. Automated Testing of Software that Uses Ma-\n",
            "chine Learning APIs. In IEEE/ACM International\n",
            "Conference on Software Engineering (ICSE), pages\n",
            "212–224.\n",
            "Yao Wan, Zhou Zhao, Min Yang, Guandong Xu,\n",
            "Haochao Ying, Jian Wu, and Philip S. Yu. 2018. Im-\n",
            "proving Automatic Source Code Summarization via\n",
            "Deep Reinforcement Learning. In Proceedings of the\n",
            "ACM/IEEE International Conference on Automated\n",
            "Software Engineering (ASE), pages 397–407.\n",
            "Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Man-\n",
            "dlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and An-\n",
            "ima Anandkumar. 2023a. Voyager: An Open-ended\n",
            "Embodied Agent with Large Language Models. In\n",
            "arXiv preprint arXiv:2305.16291.\n",
            "Lei Wang, Jingsen Zhang, Hao Yang, Zhiyuan Chen,\n",
            "Jiakai Tang, Zeyu Zhang, Xu Chen, Yankai Lin, Rui-\n",
            "hua Song, Wayne Xin Zhao, Jun Xu, Zhicheng Dou,\n",
            "Jun Wang, and Ji-Rong Wen. 2023b. When Large\n",
            "Language Model based Agent Meets User Behavior\n",
            "Analysis: A Novel User Simulation Paradigm. In\n",
            "arXiv preprint arXiv:2306.02552.\n",
            "Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu,\n",
            "Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and\n",
            "Zhifang Sui. 2023c. Large Language Models are not\n",
            "Fair Evaluators. In arXiv preprint arXiv:2305.17926.\n",
            "Song Wang, Taiyue Liu, and Lin Tan. 2016. Automati-\n",
            "cally Learning Semantic Features for Defect Predic-\n",
            "tion. In Proceedings of the International Conference\n",
            "on Software Engineering (ICSE), pages 297–308.\n",
            "Song Wang, Nishtha Shrestha, Abarna Kucheri Subbu-\n",
            "raman, Junjie Wang, Moshi Wei, and Nachiappan\n",
            "Nagappan. 2021. Automatic Unit Test Generation\n",
            "for Machine Learning Libraries: How Far Are We?\n",
            "In IEEE/ACM International Conference on Software\n",
            "Engineering (ICSE), pages 1548–1560.\n",
            "Xinyuan Wang, Chenxi Li, Zhen Wang, Fan Bai, Hao-\n",
            "tian Luo, Jiayou Zhang, Nebojsa Jojic, Eric P. Xing,\n",
            "and Zhiting Hu. 2023d.\n",
            "PromptAgent: Strategic\n",
            "Planning with Language Models Enables Expert-\n",
            "level Prompt Optimization.\n",
            "In arXiv preprint\n",
            "arXiv:2310.16427.\n",
            "Zhilin Wang, Yu Ying Chiu, and Yu Cheung Chiu.\n",
            "2023e. Humanoid Agents: Platform for Simulating\n",
            "Human-like Generative Agents. In arXiv preprint\n",
            "arXiv:2310.05418.\n",
            "Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,\n",
            "Barret Zoph, Sebastian Borgeaud, Dani Yogatama,\n",
            "Maarten Bosma, Denny Zhou, Donald Metzler, et al.\n",
            "2022a. Emergent Abilities of Large Language Mod-\n",
            "els. In arXiv preprint arXiv:2206.07682.\n",
            "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\n",
            "Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,\n",
            "et al. 2022b. Chain-of-Thought Prompting Elicits\n",
            "Reasoning in Large Language Models. In Advances\n",
            "in Neural Information Processing Systems (NeurIPS),\n",
            "volume 35, pages 24824–24837.\n",
            "Lilian Weng. 2023. LLM-powered Autonomous Agents.\n",
            "In lilianweng.github.io.\n",
            "Jonas Winkler, Jannis Grönberg, and Andreas Vogel-\n",
            "sang. 2020. Predicting How to Test Requirements:\n",
            "An Automated Approach. In Software Engineering,\n",
            "volume P-300 of LNI, pages 141–142.\n",
            "Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,\n",
            "Quoc V. Le, Denny Zhou, and Xinyun Chen. 2023a.\n",
            "Large Language Models as Optimizers. In arXiv\n",
            "preprint arXiv:2309.03409.\n",
            "Rui Yang, Lin Song, Yanwei Li, Sijie Zhao, Yixiao\n",
            "Ge, Xiu Li, and Ying Shan. 2023b.\n",
            "GPT4Tools:\n",
            "Teaching Large Language Model to Use Tools via\n",
            "Self-instruction. In Advances in Neural Information\n",
            "Processing Systems (NeurIPS).\n",
            "Murat Yilmaz, Rory V O’Connor, and Paul Clarke. 2012.\n",
            "A Systematic Approach to the Comparison of Roles\n",
            "in the Software Development Processes. In Inter-\n",
            "national Conference on Software Process Improve-\n",
            "ment and Capability Determination, pages 198–209.\n",
            "Springer.\n",
            "Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng Guo,\n",
            "Junqi Dai, Xuanjing Huang, and Xipeng Qiu. 2023.\n",
            "Exchange-of-Thought: Enhancing Large Language\n",
            "\fModel Capabilities through Cross-Model Communi-\n",
            "cation. In Proceedings of the 2023 Conference on\n",
            "Empirical Methods in Natural Language Processing\n",
            "(EMNLP), pages 15135–15153.\n",
            "An Zhang, Leheng Sheng, Yuxin Chen, Hao Li, Yang\n",
            "Deng, Xiang Wang, and Tat-Seng Chua. 2023a. On\n",
            "Generative Agents in Recommendation. In arXiv\n",
            "preprint arXiv:2310.10108.\n",
            "Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,\n",
            "Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,\n",
            "Yulong Chen, et al. 2023b. Siren’s Song in the AI\n",
            "Ocean: A Survey on Hallucination in Large Lan-\n",
            "guage Models. In arXiv preprint arXiv:2309.01219.\n",
            "Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu\n",
            "Lin, Yong-Jin Liu, and Gao Huang. 2023. ExpeL:\n",
            "LLM Agents Are Experiential Learners. In AAAI\n",
            "Conference on Artificial Intelligence (AAAI).\n",
            "Tianming Zhao, Chunyang Chen, Yuanning Liu, and\n",
            "Xiaodong Zhu. 2021. GUIGAN: Learning to Gener-\n",
            "ate GUI Designs Using Generative Adversarial Net-\n",
            "works. In IEEE/ACM International Conference on\n",
            "Software Engineering (ICSE), pages 748–760.\n",
            "Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou,\n",
            "Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan\n",
            "Bisk, Daniel Fried, Uri Alon, et al. 2023a.\n",
            "We-\n",
            "bArena: A Realistic Web Environment for Build-\n",
            "ing Autonomous Agents.\n",
            "In arXiv preprint\n",
            "arXiv:2307.13854.\n",
            "Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li,\n",
            "Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang,\n",
            "Jing Chen, Ruipu Wu, Shuai Wang, Shiding Zhu, Jiyu\n",
            "Chen, Wentao Zhang, Ningyu Zhang, Huajun Chen,\n",
            "Peng Cui, and Mrinmaya Sachan. 2023b. Agents: An\n",
            "Open-source Framework for Autonomous Language\n",
            "Agents. In arXiv preprint arXiv:2309.07870.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Conceptualizer\n",
        "\n",
        "conceptualizer = AssistantAgent(\n",
        "        name=\"conceptualizer\",\n",
        "        description=\"\"\"\n",
        "          Given a text of a scientific paper, this agent will return\n",
        "          a conceptualization -- a list of topics discussed in the paper\n",
        "          as well as the key contributions delivered.\n",
        "        \"\"\",\n",
        "        model_client=text_model_client,\n",
        "        system_message=\"\"\"\n",
        "          You are a professor of computer science specialized in multi agent systems\n",
        "          and generative AI. Given a text of a scientific paper, write a conceptualization\n",
        "          of it -- provide the title as well as the structure of the paper and key contributions delivered.\n",
        "          Write structured, using headers and bullet points. Provide short descriptions\n",
        "          of key contributions. Fit your answer in 500 words.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "\n",
        "# CHECK IF CONCEPTUALIZATION WORKS\n",
        "\n",
        "async def concept_run(paper_text: str) -> None:\n",
        "    response = await conceptualizer.on_messages(\n",
        "        [TextMessage(content=paper_text, source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    #print(paper_text)\n",
        "    #print(response.inner_messages)\n",
        "    print(response.chat_message.models_usage)\n",
        "    #print(response.chat_message.content)\n",
        "    return response.chat_message.content\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "conceptualization_test = await concept_run(test_paper_text)  # we'll need the variable later for testing of other agents\n",
        "print(conceptualization_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l4vZ0eHvkRw",
        "outputId": "33ddad87-a2d1-4651-ab89-2a52d89891e8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RequestUsage(prompt_tokens=17131, completion_tokens=664)\n",
            "The paper introduces ChatDev, a framework for software development using a chat-based system powered by language models (LLMs). The system is composed of multiple specialized agents, each with a specific role (e.g., programmer or reviewer) that work collaboratively through multi-turn dialogues, using unique roles, communication patterns, and context awareness to improve software's quality in the design, coding, and testing phases. The paper highlights that the use of linguistic communication facilitates multi-agent collaboration and provides the novel concept of \"Communicative Dehallucination\" to address coding hallucinations. Results indicate that the proposed paradigm enhances the completeness, executability, and consistency of software generated, and outperforms existing LLM-powered software development methods. The findings suggest that using cooperative agents through effective communication for software optimization is a promising approach.\n",
            "\n",
            "Contributions:\n",
            "\n",
            "1. Introducing ChatDev:\n",
            "   - A multi-agent, chat-based framework for software development utilizing LLMs to enhance collaboration.\n",
            "\n",
            "2. Role-based system design:\n",
            "   - Assigning specific roles to agents, such as CEO, CTO, programmer, reviewer, and tester, enhancing their ability to effectively contribute to various phases of software development.\n",
            "\n",
            "3. Communication pattern and chat chain concept:\n",
            "   - Chat chain organizes communication targets to streamline the development process, optimizing the system through unified language-based communication.\n",
            "\n",
            "4. Communicative dehallucination:\n",
            "   - A communication mechanism for reducing coding hallucinations, enabling agents to request more detailed information before giving direct responses, improving the precision of solutions.\n",
            "\n",
            "5. Implementation and evaluation:\n",
            "   - Experimental results demonstrate ChatDev's advantages, improved software quality, and outperformance compared to existing LLM-powered software development methods.\n",
            "\n",
            "6. Ablation study and analysis:\n",
            "   - Investigation of key components within the multi-agent cooperation framework sheds light on their significance, such as the benefits of agent roles and the impact of the chat chain structure.\n",
            "\n",
            "7. Communication analysis:\n",
            "   - Analysis of dialogues between agents reveals that cooperation through effective communication for software optimization is a promising approach.\n",
            "\n",
            "Future directions and potential improvements:\n",
            "\n",
            "- Addressing the limitations of LLMs, such as overestimating capabilities, difficulty capturing complex details, and high computational demands, is crucial for improving their performance in multi-agent collaboration settings.\n",
            "- Developing tools to help users define accurate and detailed software requirements is essential for addressing the challenges agents face in understanding complex tasks.\n",
            "- Creating methods to evaluate software not just on completeness, executability, and consistency, but on functionalities, robustness, safety, and user-friendliness.\n",
            "- Increasing agent capabilities to minimize interactions, making them more efficient and reducing economic and environmental impact.\n",
            "\n",
            "The proposed ChatDev framework demonstrates the potential of LLM-powered multi-agent collaboration in software development, inspiring further research into the use of language for optimizing development processes and the empowering role of AI in automated software solutions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Summarizer agent\n",
        "\n",
        "\n",
        "summarizer_agent = AssistantAgent(\n",
        "    name=\"summarizer\",\n",
        "    description=\"\"\"\n",
        "      Expects a conceptualization of a paper (title, structure of the paper, key points and contributions)\n",
        "      and write a summary of the paper.\n",
        "    \"\"\",\n",
        "    model_client=text_model_client,\n",
        "    system_message=\"\"\"\n",
        "        You are a professor of computer science\n",
        "        and also qualified and experienced reviewer and critic of scientific papers.\n",
        "        You will be given a conceptualization of a paper (title, structure of the paper, key points and contributions).\n",
        "        Summarize the paper using the points provided in conceptualisation.\n",
        "        You must fit your summarization in 500 words.\n",
        "        It is very important to depict the key contributions of the paper.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# CHECK IF SUMMARIZING WORKS\n",
        "\n",
        "async def summarizer_run(paper_text: str, conceptualization: str) -> None:\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "      ------start conceptualization-------\n",
        "      {conceptualization}\n",
        "      ------end conceptualization-------\n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "    response = await summarizer_agent.on_messages(\n",
        "        [TextMessage(content=prompt, source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    #print(paper_text)\n",
        "    #print(response.inner_messages)\n",
        "    print(response.chat_message.models_usage)\n",
        "    return response.chat_message.content\n",
        "\n",
        "\n",
        "summarization = await summarizer_run(test_paper_text, conceptualization_test)\n",
        "print(summarization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktdy24vWxWgE",
        "outputId": "ba4d6b6c-7a4a-4e31-9c66-9e98f7368433"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RequestUsage(prompt_tokens=787, completion_tokens=449)\n",
            "Title: \"ChatDev: A Multi-Agent Framework for Software Development Using conversational AI\"\n",
            "\n",
            "This paper presents the development and introduction of ChatDev, a novel, multi-agent software development framework that leverages the power of Language Models (LLMs) to streamline the software development process. The framework revolves around a chat-based system, where multiple agents with specialized roles collaborate in a conversational manner to produce high-quality software.\n",
            "\n",
            "The system's architecture includes agents taking on roles such as the CEO, CTO, programmer, reviewer, and tester, thereby enhancing their contributions to the various stages of software development. The use of an organized chat-chain system overlooks the fluid communication, optimizing the overall development process through a unified language-based exchange of ideas.\n",
            "\n",
            "Introducing the concept of \"Communicative Dehallucination,\" this paper addresses the coding hallucinations that may arise in an autonomous, conversational system, where agents request further details to clarify issues before providing a solution. This approach enhances the precision of the solutions generated, improving the overall software quality.\n",
            "\n",
            "The paper presents empirical evidence demonstrating the merits of ChatDev, including improved completeness, executability, and consistency, compared to existing LLM-powered software development methods. Moreover, an in-depth analysis of the dialogues between the agents reveals the effectiveness of their cooperative approach for software optimization.\n",
            "\n",
            "Future research areas for this field include tackling the limitations of LLMs, such as overestimating capabilities, difficulty capturing complex details, and high computational demands; developing tools for defining precise software requirements; creating evaluation methods to analyze software on functionalities, robustness, safety, and user-friendliness; and reducing the number of interactions to make the system more efficient, thereby minimizing economic and environmental impact.\n",
            "\n",
            "The proposed ChatDev framework offers immense potential for the future of AI in software development. By cultivating an environment of conversational collaboration, this framework underscores the power of leveraging LLMs in automating software development processes, inspiring further exploration and research in the field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5reIaye0yi4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
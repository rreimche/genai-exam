{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3tlC6kP2Af3e7yomlgjCj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rreimche/genai-exam/blob/main/LitRev2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites:\n",
        "\n",
        "- Google Colab\n",
        "- Access to a Google Colab Secret named \"HF_API_TOKEN\" containing a Huggingface API token with read access."
      ],
      "metadata": {
        "id": "FxKuuRqaa1ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "XSEOGHM1apvo"
      },
      "outputs": [],
      "source": [
        "#@title Settings\n",
        "from google.colab import userdata\n",
        "\n",
        "download_dir = \"papers\"  # directory name to download papers to revie to\n",
        "huggingface_apikey = userdata.get('HF_API_TOKEN')  # use colab secrets to store the huggingface api key\n",
        "groq_key = userdata.get('GROQ_KEY')  #  use colab secrets to store the huggingface api key\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Declare bibtex references and parse them into a variable for later usage\n",
        "\n",
        "\n",
        "bibtext_references = \"\"\"\n",
        "\n",
        "\n",
        "@misc{qian2024chatdevcommunicativeagentssoftware,\n",
        "      title={ChatDev: Communicative Agents for Software Development},\n",
        "      author={Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},\n",
        "      year={2024},\n",
        "      eprint={2307.07924},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.SE},\n",
        "      url={https://arxiv.org/abs/2307.07924},\n",
        "},\n",
        "\n",
        "@misc{nguyen2024agilecoderdynamiccollaborativeagents,\n",
        "      title={AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology},\n",
        "      author={Minh Huynh Nguyen and Thang Phan Chau and Phong X. Nguyen and Nghi D. Q. Bui},\n",
        "      year={2024},\n",
        "      eprint={2406.11912},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.SE},\n",
        "      url={https://arxiv.org/abs/2406.11912},\n",
        "},\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "hghBKNhCa_3B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "!pip install -q autogen arxiv scholarly crossrefapi beautifulsoup4 requests cloudscraper pymupdf nltk autogen-agentchat autogen-ext[openai] groq pymupdf;\n",
        "!pip install -q --pre bibtexparser;"
      ],
      "metadata": {
        "id": "Asy4oaZmbF2F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preparation for agents: model client connections\n",
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "from autogen_core.tools import FunctionTool\n",
        "from autogen_core.models import UserMessage\n",
        "#from autogen_agentchat.ui import Console\n",
        "from autogen_core import CancellationToken\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "\n",
        "# INSTANTIATE MODEL CLIENTS\n",
        "\n",
        "# This client will be used for paper summarization\n",
        "text_model_client = OpenAIChatCompletionClient(\n",
        "    #model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\",\n",
        "    #model=\"facebook/bart-large-xsum\",\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    #model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
        "    base_url=\"https://router.huggingface.co/hf-inference/v1\",\n",
        "    api_key=huggingface_apikey,\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# We need another inference point for downloader agent,\n",
        "# because huggingface can't serve reflection on tool use\n",
        "# so that autogen agent understands it\n",
        "tool_model_client = OpenAIChatCompletionClient(\n",
        "    #model=\"llama3-70b-8192\",\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    #model=\"deepseek-r1-distill-qwen-32b\",\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=groq_key,\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# CHECK CONNECTION\n",
        "\n",
        "async def check_model_connect() -> None:\n",
        "    messages = [\n",
        "        UserMessage(content=\"What is the capital of France?\", source=\"user\"),\n",
        "    ]\n",
        "    response = await text_model_client.create(messages=messages)\n",
        "    response_downloader = await tool_model_client.create(messages=messages)\n",
        "\n",
        "    print(response.content)\n",
        "    print(response_downloader.content)\n",
        "\n",
        "await check_model_connect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oheTZ2eGbS48",
        "outputId": "6ccf6b72-297f-41d4-8d0e-43ee4b21fac5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris. It is also one of the most famous cities in the world, known for its architecture, art, fashion, and cuisine. Paris is home to many iconic landmarks, such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral.\n",
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloader agent\n",
        "import arxiv\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from autogen_core.models import ChatCompletionClient\n",
        "from autogen_core import message_handler\n",
        "\n",
        "# HELPER AND TOOL FUNCTIONS\n",
        "\n",
        "def maybe_create_dir(donwload_dir: str) -> None:\n",
        "    \"\"\"\n",
        "        A helper function to create the downloads directory\n",
        "        in colab root if the directory is not yet present.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        os.makedirs(donwload_dir, exist_ok=True)\n",
        "        #print(f\"Directory '{download_dir}' created successfully.\")\n",
        "    except OSError as e:\n",
        "        raise Exception(f\"Error creating directory '{download_dir}': {e}\")\n",
        "\n",
        "def download_paper(eprint_id: str) -> str:\n",
        "    \"\"\"\n",
        "        Receives a eprint_id of a paper from arxiv, downloads the specified paper\n",
        "        and saves it in downloads directory.\n",
        "        The filepath of the downloaded paper is in the resulting dictionary\n",
        "        with the key \"filepath\".\n",
        "\n",
        "        :param eprint_id: string, the arxiv eprint_id.\n",
        "        :return: string with filepath of the downloaded paper.\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(eprint_id) > 0, \"eprint_id cannot be empty\"\n",
        "\n",
        "    result = {\n",
        "        \"eprint_id\": eprint_id,\n",
        "        \"success\": False,\n",
        "        \"filepath\": None,\n",
        "        }\n",
        "\n",
        "\n",
        "    if eprint_id:\n",
        "        #print(f\"{datetime.datetime.now()} - Trying arXiv for: {eprint_id}\")\n",
        "        try:\n",
        "            client = arxiv.Client()\n",
        "            search = arxiv.Search(id_list=[eprint_id], max_results=1)\n",
        "\n",
        "            #arxiv_result = next(search.results(), None)\n",
        "            arxiv_result = next(client.results(search))\n",
        "            if arxiv_result:\n",
        "                #print(f\"  Found on arXiv: {arxiv_result.title}\")\n",
        "                maybe_create_dir(download_dir)\n",
        "                filepath = os.path.join(download_dir, f\"{arxiv_result.title.replace(' ', '_')}.pdf\")\n",
        "                arxiv_result.download_pdf(filename=filepath)\n",
        "                result[\"success\"] = True\n",
        "                result[\"filepath\"] = filepath\n",
        "                #print(f\"  Download successful: {filepath}\")\n",
        "            else:\n",
        "                # print(f\"  No arXiv result found for ID {eprint_id}.\")\n",
        "                raise Exception(f\"ERROR: No arXiv result found for ID {eprint_id}.\")\n",
        "                #return f\"ERROR: No arXiv result found for ID {eprint_id}.\"\n",
        "\n",
        "        except Exception as e:\n",
        "            #print(f\"arXiv download failed for: {eprint_id}: {e}\")\n",
        "            raise Exception(f\"ERROR: arXiv download failed for: {eprint_id}: {e}\")\n",
        "            #return f\"ERROR: arXiv download failed for: {eprint_id}: {e}\"\n",
        "\n",
        "    # Check if the download was NOT successful\n",
        "    if not result[\"success\"]:\n",
        "        #print(f\"{datetime.datetime.now()} - Download failed or not attempted for: {eprint_id}\")\n",
        "        raise Exception(f\"ERROR: Download failed or not attempted for: {eprint_id}\")\n",
        "        #return f\"ERROR: Download failed or not attempted for: {eprint_id}\"\n",
        "\n",
        "    return result[\"filepath\"]\n",
        "\n",
        "\n",
        "# DOWNLOADER AGENT WITH TOOL\n",
        "\n",
        "def create_downloader(given_name: str) -> AssistantAgent:\n",
        "    downloader_tool = FunctionTool(download_paper, description=\"Given a string denoting an eprint_id of a page on arxiv, downloads a paper\")\n",
        "\n",
        "    return AssistantAgent(\n",
        "        name=given_name,\n",
        "        description=\"An agent that uses downloader tool to download a paper from Arxiv identified by a eprint_id\",\n",
        "        model_client=tool_model_client,\n",
        "        tools=[downloader_tool],\n",
        "        reflect_on_tool_use=True,\n",
        "        system_message=\"\"\"\n",
        "            Use downloader tool to download specified paper(s) from arxiv.\n",
        "            Here is an example of how you must respond in success case:\n",
        "              'mypapers/veryinterstingpaper.pdf'\n",
        "\n",
        "            Very important: You MUST return the full filepath of the downloaded\n",
        "            paper EXACTLY as it was given by the downloader tool.\n",
        "\n",
        "            If download was not successful, respond like this:\n",
        "              'ERROR: Download for paper with eprint id XXX failed for the following reason: REASON'.\n",
        "          \"\"\",\n",
        "    )\n",
        "\n",
        "# CHECK IF DOWNLOAD WORKS\n",
        "\n",
        "async def downloader_run() -> None:\n",
        "    response = await create_downloader(\"Test\").on_messages(\n",
        "        [TextMessage(content=\"Download the paper with eprint_id 2402.01411\", source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message)\n",
        "    print(response.chat_message.content)\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "#await downloader_run()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oirHwIBNc_-a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Agents to get paper text: Informant and Parser\n",
        "import arxiv\n",
        "from typing import Dict\n",
        "import pymupdf\n",
        "import requests\n",
        "from autogen_agentchat.ui import Console\n",
        "\n",
        "def get_arxiv_data(eprint_id: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Given arxiv eprint_id of a scientific paper, returns title of the paper\n",
        "    along with the PDF URL.\n",
        "\n",
        "    :param eprint_id: string, the arxiv eprint_id.\n",
        "    :return: dictionary with keys \"title\" and \"pdf_url\".\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(eprint_id) > 0, \"eprint_id cannot be empty\"\n",
        "\n",
        "    client = arxiv.Client()\n",
        "    search = arxiv.Search(id_list=[eprint_id], max_results=1)\n",
        "\n",
        "    try:\n",
        "\n",
        "        arxiv_result = next(client.results(search))\n",
        "        if arxiv_result:\n",
        "            return {\n",
        "                \"title\": arxiv_result.title,\n",
        "                \"pdf_url\": arxiv_result.pdf_url,\n",
        "            }\n",
        "        else:\n",
        "            raise Exception(f\"ERROR: No arXiv result found for ID {eprint_id}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"ERROR: getting data from arxiv failed for: {eprint_id}: {e}\")\n",
        "\n",
        "\n",
        "def parse_paper(url: str) -> str:\n",
        "    \"\"\"\n",
        "    Given URL of a PDF as a string, returns the contents as a string\n",
        "\n",
        "    :param url: string, the URL of the PDF.\n",
        "    :return: string with the contents of the PDF.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        r = requests.get(url)\n",
        "        data = r.content\n",
        "        doc = pymupdf.Document(stream=data)\n",
        "        text = chr(12).join([page.get_text() for page in doc])\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        # print(f\"Error parsing {title} ({filepath}): {e}\")\n",
        "        raise Exception(f\"ERROR: Error parsing the paper at {url}: {e}\")\n",
        "\n",
        "\n",
        "async def get_summary(eprint_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Takes a eprint id from arxiv and returns the summarization of the related paper.\n",
        "\n",
        "    :param eprint_id: string, the arxiv eprint_id.\n",
        "    :return: string with PDF contents.\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(eprint_id) > 0, \"eprint_id cannot be empty\"\n",
        "\n",
        "\n",
        "\n",
        "    try:\n",
        "        arxiv_data = get_arxiv_data(eprint_id)\n",
        "        #print(arxiv_data[\"pdf_url\"])\n",
        "        text = parse_paper(arxiv_data[\"pdf_url\"])\n",
        "\n",
        "        concept_prompt = f\"\"\"\n",
        "          You are a professor of computer science specialized in multi agent systems\n",
        "          and generative AI. Your task ist to summarize a certain scientific paper.\n",
        "\n",
        "          Here is the text of the paper:\n",
        "\n",
        "          -------start of paper--------\n",
        "          {text}\n",
        "          -------end of paper--------\n",
        "\n",
        "          Use the provided text to write the summarization.\n",
        "          Write consice and clear using the highest academic standards.\n",
        "          It is very important to provide short descriptions of key contributions.\n",
        "          Fit your answer in 500 words.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "        concept = await text_model_client.create([UserMessage(content=concept_prompt, source=\"user\")])\n",
        "        #print(concept)\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"ERROR: Error downloading, parsing or summarizing the paper identified by eprint id {eprint_id}: {e}\")\n",
        "\n",
        "    return concept\n",
        "\n",
        "\n",
        "tool_getsummary = FunctionTool(\n",
        "    get_summary,\n",
        "    description = \"Takes a eprint id of a paper published on arxiv and returns a summarization of the related paper.\"\n",
        ")\n",
        "\n",
        "\n",
        "paper_summarizer = AssistantAgent(\n",
        "    name=\"summarizer\",\n",
        "    description=\"Provided with arxiv eprint id, returns a summarization of the related paper\",\n",
        "    model_client=tool_model_client,\n",
        "    tools=[tool_getsummary],\n",
        "    reflect_on_tool_use=True,\n",
        "    system_message=\"\"\"\n",
        "        You are a a professor of computer science. Use eprint ids of papers\n",
        "        published at Arxiv to use the tool you're equipped with (tool_getsummary),\n",
        "        which will give you the summarization of the related paper.\n",
        "        Give the text of the paper back as your answer. Answer concise\n",
        "        and structured.\n",
        "\n",
        "        Use only one eprint id at a time, chose the one that was not already summarized.\n",
        "\n",
        "        Avoid doing any other work like planning, or writing reviews or calling other tools.\n",
        "    \"\"\"\n",
        "\n",
        ")\n",
        "\n",
        "# CHECK IF WORKS\n",
        "\n",
        "async def get_paper_summary_run() -> None:\n",
        "    #response_i = await paper_informant.on_messages(\n",
        "    #    [TextMessage(content=\"Give me the infos of the paper with eprint_id 2307.07924\", source=\"user\")],\n",
        "    #    cancellation_token=CancellationToken(),\n",
        "    #)\n",
        "\n",
        "    #prev_answer = response_i.chat_message.content\n",
        "\n",
        "    #print(prev_answer)\n",
        "\n",
        "    #response_p = await paper_parser.on_messages(\n",
        "    #    [TextMessage(content=f\"Give me the text of paper, which url is specified in the following text: {prev_answer}\", source=\"user\")],\n",
        "    #    cancellation_token=CancellationToken(),\n",
        "    #)\n",
        "\n",
        "    # for deeper debugging\n",
        "    #await Console(\n",
        "    #    paper_conceptualizer.on_messages_stream(\n",
        "    #        [TextMessage(content=f\"Give me the concept of a paper with eprint_id 2307.07924\", source=\"user\")],\n",
        "    #        cancellation_token=CancellationToken(),\n",
        "    #    ),\n",
        "    #    output_stats=True,  # Enable stats printing.\n",
        "    #)\n",
        "\n",
        "    response = await paper_summarizer.on_messages(\n",
        "        [TextMessage(content=\"Give me a summarization of the paper with eprint_id 2307.07924\", source=\"user\")],\n",
        "        cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message)\n",
        "    #print(response.chat_message.content)\n",
        "\n",
        "    return response.chat_message.content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "test_paper_summary = await get_paper_summary_run()\n",
        "print(test_paper_summary)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vxgO7DIjdVIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83314b13-7e6a-4bb3-e244-5d6906cc3d7f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The paper \"ChatDev: Communicative Agents for Software Development\" introduces a novel chat-powered software development framework that leverages large language models (LLMs) in a multi-agent collaboration setting. The framework is designed to address the technical inconsistencies across various stages in the waterfall model by implementing a unified language-based communication system. \n",
            "\n",
            "The key contributions of this paper include the paradigm of creating a unified language-based communication system for software development, the use of a chain-structured workflow for efficient cooperation among agents, the communicative dehallucination mechanism for reducing coding hallucinations, and the chain-style analysis demonstrating the agents' communication dynamics during the development process.\n",
            "\n",
            "The proposed chat-powered software development framework, referred to as ChatDev, presents a unique application of LLMs in a coordinated environment that fosters multi-agent collaboration and produces high-quality solutions. This distinguishes it from previous studies that solely focus on single-agent methods. The findings indicate that ChatDev outperforms existing methods across various metrics, including completeness, executability, and consistency.\n",
            "\n",
            "Through careful evaluation of key components and mechanisms in the framework, the study reveals that the design and its elements play a crucial role in fostering effective communication and promoting software optimization. The analysis of the agents' communication during the software development process sheds light on the static debugging dynamics in code reviews and the dynamic debugging dynamics in testing phases.\n",
            "\n",
            "This research builds upon the significance of multi-agent cooperation and emphasizes the role of effective communication in software development, potentially paving the way for further advancements in the field of LLMs, agent-based software development, and automated software production. The paper concludes by discussing limitations and potential future directions for research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reviewer agent\n",
        "from typing import List\n",
        "\n",
        "\n",
        "reviewer = AssistantAgent(\n",
        "    name=\"reviewer\",\n",
        "    description=\"\"\"\n",
        "        Given a several summarizations (short description of important paper contents)\n",
        "        for several scientific papers, writes a scientific literature review.\n",
        "    \"\"\",\n",
        "    model_client=text_model_client,\n",
        "    #system_message=\"\"\"\n",
        "#        You are a professor of computer science preparing a review\n",
        "#        of recent publications on the topic of multi-agent llm-based systems\n",
        "#        for end-to-end software development (such systems receive requirements\n",
        "#        as input and deliver a ready system as output with optional system-user\n",
        "#        interactions inbetween). You will receive the conceptualisations of\n",
        "#        several papers (that is, consice enumeration of important contributions of the papers)\n",
        "#        and write a concise and factually detailed literature review.\n",
        "#        Stick to scientific standards regarding style and rigour.\n",
        "#        You must fit your review in 500 words.\n",
        "\n",
        "#        It is very important to depict the key contributions of the papers.\n",
        "#\"\"\",\n",
        "    system_message=\"\"\"\n",
        "        You are a professor of computer science preparing a review\n",
        "        of recent publications on the topic of multi-agent llm-based systems\n",
        "        for end-to-end software development (such systems receive requirements\n",
        "        as input and deliver a ready system as output with optional system-user\n",
        "        interactions inbetween). Use provided conceptualisations of\n",
        "        several papers (that is, consice enumeration of important contributions of the papers)\n",
        "        and write a concise and factually detailed literature review.\n",
        "        Stick to scientific standards regarding style and rigour, but provide\n",
        "        only the review text, omitting authors, refences and other metainformation.\n",
        "        You must fit your review in 500 words.\n",
        "\n",
        "        It is very important to depict the key contributions of the papers.\n",
        "\n",
        "        You do not do any other work like downloading, parsing, writing conceptualizations or summarizations.\n",
        "\"\"\",\n",
        ")\n",
        "\n",
        "\n",
        "# CHECK IF REVIEWING WORKS\n",
        "\n",
        "async def reviewer_run(summarizations: List[str]) -> str:\n",
        "\n",
        "    prompt_rev = f\"Here are {len(summarizations)} paper summarizations that you need to review:\\n\"\n",
        "    for summarization in summarizations:\n",
        "        prompt_rev += f\"------start summarizations-------\\n{summarization}\\n------end summarizations-------\\n\"\n",
        "    prompt_rev += \"Write the scientific literature review.\"\n",
        "\n",
        "\n",
        "    response = await reviewer.on_messages(\n",
        "       [TextMessage(content=prompt_rev, source=\"user\")],\n",
        "       cancellation_token=CancellationToken(),\n",
        "    )\n",
        "\n",
        "    #print(paper_text)\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message.models_usage)\n",
        "    return response.chat_message.content\n",
        "\n",
        "\n",
        "\n",
        "# Use asyncio.run(assistant_run()) when running in a script.\n",
        "review = await reviewer_run([test_paper_summary, test_paper_summary])\n",
        "print(review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5reIaye0yi4x",
        "outputId": "f2cd7872-cb40-4322-bad4-4f2c679190ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: A Review of Recent Advances in Multi-Agent Large Language Model (LLM)-Based Systems for End-to-End Software Development\n",
            "\n",
            "In recent scholarly discourse, significant progress has been made in the development of multi-agent systems that harness the potential of large language models (LLMs) for end-to-end software creation. Among these advancements, the paper \"ChatDev: Communicative Agents for Software Development\" stands out, proposing a novel chat-powered software development framework.\n",
            "\n",
            "The ChatDev framework uniqueley integrates LLMs into a multi-agent collaboration setting, using a unified language-based communication system to mitigate technical inconsistencies throughout the waterfall model. The framework's agents are designed to conduct multi-turn dialogues, thereby optimizing solutions and enhancing software quality.\n",
            "\n",
            "Three key contributions have emerged from this research:\n",
            "\n",
            "1. The development of a unified language-based communication system for software development, fostering consistent interaction among agents and facilitating efficient collaboration.\n",
            "2. The implementation of a chain-structured workflow, ensuring efficient cooperation among agents as they progressively contribute to the software development process.\n",
            "3. The introduction of a communicative dehallucination mechanism, offering a means to mitigate coding hallucinations and promote the development of robust, error-free software.\n",
            "\n",
            "MIT analysis of the ChatDev framework's performance indicates superiority over existing methods in terms of completeness, executability, and consistency. The study also underscores the crucial role of multi-agent cooperation and effective communication in software development, offering insights into static debugging dynamics in code reviews and dynamic debugging dynamics during testing phases.\n",
            "\n",
            "The ChatDev framework signifies a significant stride towards automated software production by capitalizing on the capabilities of LLMs and multi-agent cooperation. With these advancements, we envision continued growth in the application of artificial intelligence and machine learning in the software development field, paving the way for more efficient and effective production processes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Planner\n",
        "\n",
        "planner = AssistantAgent(\n",
        "    name=\"planner\",\n",
        "    description=\"Plans the literature review process, assigns tasks to other agents.\",\n",
        "    model_client=tool_model_client,\n",
        "    system_message=\"\"\"\n",
        "      Your task is to plan scientific review process for given papers, assigning tasks to agents.\n",
        "      You have several agents in your disposition:\n",
        "      1. summarizer: uses arxiv eprint ids to summarize the related papers\n",
        "      2. reviewer: uses the available summarizations to write a literature review\n",
        "\n",
        "      When assigning tasks, use this format:\n",
        "      1. <agent> : <task>\n",
        "\n",
        "      Only plan the work of others, do not do any work yourself.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Check planner\n",
        "async def planner_run(task: str) -> None:\n",
        "\n",
        "\n",
        "    await Console(\n",
        "        planner.on_messages_stream(\n",
        "            [TextMessage(content=task, source=\"user\")],\n",
        "            cancellation_token=CancellationToken(),\n",
        "        ),\n",
        "        output_stats=True,\n",
        "    )\n",
        "\n",
        "    #print(paper_text)\n",
        "    #print(response.inner_messages)\n",
        "    #print(response.chat_message.models_usage)\n",
        "\n",
        "await planner_run(\"Write a literature review on the papers, identified by the following arxiv eprint ids: 2307.07924, 2406.11912\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj0PbKrwCTpp",
        "outputId": "40879ce3-ef5f-486b-fb3e-72bc7c964659"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- planner ----------\n",
            "To create a literature review on the papers with arxiv eprint ids 2307.07924 and 2406.11912, I will assign the following tasks:\n",
            "\n",
            "1. **summarizer** : Summarize the paper with arxiv eprint id 2307.07924\n",
            "2. **summarizer** : Summarize the paper with arxiv eprint id 2406.11912\n",
            "3. **reviewer** : Write a literature review using the summarizations of the papers with arxiv eprint ids 2307.07924 and 2406.11912\n",
            "[Prompt tokens: 163, Completion tokens: 125]\n",
            "---------- Summary ----------\n",
            "Number of inner messages: 0\n",
            "Total prompt tokens: 163\n",
            "Total completion tokens: 125\n",
            "Duration: 0.91 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preparing the task for the system\n",
        "from bibtexparser.bparser import BibTexParser\n",
        "from bibtexparser.bwriter import BibTexWriter\n",
        "from bibtexparser.bibdatabase import BibDatabase\n",
        "from bibtexparser.customization import convert_to_unicode\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def parse_bibtex_string(bibtex_string):\n",
        "\n",
        "    if not bibtex_string:\n",
        "        return []  # Handle empty input\n",
        "\n",
        "    try:\n",
        "        parser = BibTexParser()\n",
        "        parser.customization = convert_to_unicode\n",
        "        parser.ignore_nonstandard_strings = True  # Avoid errors with non-standard fields\n",
        "        db = parser.parse(bibtex_string)\n",
        "        return db.entries\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing BibTeX string: {e}\")\n",
        "        return None  # Indicate parsing failure\n",
        "\n",
        "def check_parsed_bibtex(items: List[dict])  -> None:\n",
        "    for entry in bibtex_items:\n",
        "        print(f\"Entry Type: {entry['ENTRYTYPE']}\")\n",
        "        print(f\"  Key: {entry['ID']}\")\n",
        "        for key, value in entry.items():\n",
        "            if key not in ['ENTRYTYPE', 'ID']:\n",
        "                print(f\"  {key}: {value}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "\n",
        "bibtex_items = parse_bibtex_string(bibtext_references)\n",
        "\n",
        "#check_parsed_bibtex(bibtex_items)\n",
        "\n",
        "eprints = \", \".join([item['eprint'] for item in bibtex_items])\n",
        "\n",
        "task = f\"Write a literature review on the papers, identified by the following arxiv eprint ids: {eprints}\"\n",
        "\n",
        "print(f\"THE TASK\\n{task}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "CVveN-Ln_2w_",
        "outputId": "f8d07223-0a75-460b-d67b-96fc224bd689"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE TASK\n",
            "Write a literature review on the papers, identified by the following arxiv eprint ids: 2307.07924, 2406.11912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Putting it all together\n",
        "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
        "from autogen_agentchat.teams import SelectorGroupChat\n",
        "from autogen_agentchat.ui import Console\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "text_mention_termination = TextMentionTermination(\"APPROVE\")\n",
        "max_messages_termination = MaxMessageTermination(max_messages=15)  # 6 papers to summarize + write a review review + user feedback + a bit of slack\n",
        "termination = text_mention_termination | max_messages_termination\n",
        "\n",
        "selector_prompt = \"\"\"\n",
        "  Coordinate the process of writing a literature review. For this, you have the following\n",
        "  agent roles:\n",
        "\n",
        "  {roles}\n",
        "\n",
        "  It is important to consider conversation context:\n",
        "  {history}\n",
        "\n",
        "  Read the above conversation, then select an agent from {participants} to perform the next task.\n",
        "  Make sure the planner agent has assigned tasks before other agents start working.\n",
        "  Only select one agent.\n",
        "\"\"\"\n",
        "\n",
        "team = SelectorGroupChat(\n",
        "    [planner, paper_summarizer, reviewer],\n",
        "    model_client=tool_model_client,\n",
        "    termination_condition=termination,\n",
        "    selector_prompt=selector_prompt,\n",
        "    allow_repeated_speaker=True,  # Allow an agent to speak multiple turns in a row.\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "l9iN0KER6tBp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Showtime\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "await Console(team.run_stream(task=task))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "buyARJW1AEV1",
        "outputId": "7ad5ddfe-0708-4306-ae12-01d7b4d33654"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- user ----------\n",
            "Write a literature review on the papers, identified by the following arxiv eprint ids: 2307.07924, 2406.11912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:autogen_core:Error processing publish message for reviewer_b647bb42-4f92-4f3f-a67e-24a0218b2c72/b647bb42-4f92-4f3f-a67e-24a0218b2c72\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\", line 510, in _on_message\n",
            "    return await agent.on_message(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_base_agent.py\", line 113, in on_message\n",
            "    return await self.on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 67, in on_message_impl\n",
            "    return await super().on_message_impl(message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\", line 485, in on_message_impl\n",
            "    return await h(self, message, ctx)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\", line 268, in wrapper\n",
            "    return_value = await func(self, message, ctx)  # type: ignore\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 69, in handle_request\n",
            "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\", line 748, in on_messages_stream\n",
            "    async for inference_output in self._call_llm(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\", line 869, in _call_llm\n",
            "    model_result = await model_client.create(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/autogen_ext/models/openai/_openai_client.py\", line 523, in create\n",
            "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
            "                                                                     ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\", line 1727, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1849, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1543, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\", line 1644, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.UnprocessableEntityError: Error code: 422 - {'error': 'Template error: syntax error: After the optional system message, conversation roles must alternate user/assistant/user/assistant/... (in <string>:18)', 'error_type': 'template_error'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnprocessableEntityError",
          "evalue": "Error code: 422 - {'error': 'Template error: syntax error: After the optional system message, conversation roles must alternate user/assistant/user/assistant/... (in <string>:18)', 'error_type': 'template_error'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnprocessableEntityError\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7969a642f652>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mConsole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/ui/_console.py\u001b[0m in \u001b[0;36mConsole\u001b[0;34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mstreaming_chunks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTaskResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py\u001b[0m in \u001b[0;36mrun_stream\u001b[0;34m(self, task, cancellation_token)\u001b[0m\n\u001b[1;32m    480\u001b[0m                     \u001b[0;31m# Wait for the shutdown task to finish.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                     \u001b[0;31m# This will propagate any exceptions raised.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m                     \u001b[0;32mawait\u001b[0m \u001b[0mshutdown_task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0;31m# Clear the output message queue.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py\u001b[0m in \u001b[0;36mstop_runtime\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0;31m# This will propagate any exceptions raised.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                     \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_when_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                     \u001b[0;31m# Stop the consumption of messages and end the stream.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\u001b[0m in \u001b[0;36mstop_when_idle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_when_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\u001b[0m in \u001b[0;36mstop_when_idle\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimmediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstop_when\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_period\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\u001b[0m in \u001b[0;36m_process_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_background_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_background_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\u001b[0m in \u001b[0;36m_process_publish\u001b[0;34m(self, message_envelope)\u001b[0m\n\u001b[1;32m    526\u001b[0m                     \u001b[0mresponses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore_unhandled_handler_exceptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\u001b[0m in \u001b[0;36m_on_message\u001b[0;34m(agent, message_context)\u001b[0m\n\u001b[1;32m    521\u001b[0m                                         )\n\u001b[1;32m    522\u001b[0m                                     )\n\u001b[0;32m--> 523\u001b[0;31m                                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_on_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_single_threaded_agent_runtime.py\u001b[0m in \u001b[0;36m_on_message\u001b[0;34m(agent, message_context)\u001b[0m\n\u001b[1;32m    508\u001b[0m                             \u001b[0;32mwith\u001b[0m \u001b[0mMessageHandlerContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                                     return await agent.on_message(\n\u001b[0m\u001b[1;32m    511\u001b[0m                                         \u001b[0mmessage_envelope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                                         \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_base_agent.py\u001b[0m in \u001b[0;36mon_message\u001b[0;34m(self, message, ctx)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mon_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMessageContext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_message_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\u001b[0m in \u001b[0;36mon_message_impl\u001b[0;34m(self, message, ctx)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fifo_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_message_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;31m# Release the FIFO lock to allow the next message to be processed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\u001b[0m in \u001b[0;36mon_message_impl\u001b[0;34m(self, message, ctx)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_unhandled_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_core/_routed_agent.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, message, ctx)\u001b[0m\n\u001b[1;32m    266\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Message type {type(message)} not in target types {target_types}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, message, ctx)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Pass the messages in the buffer to the delegate agent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mResponse\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_messages_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;31m# Log the response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\u001b[0m in \u001b[0;36mon_messages_stream\u001b[0;34m(self, messages, cancellation_token)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# STEP 3: Run the first inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0mmodel_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         async for inference_output in self._call_llm(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mmodel_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mmodel_client_stream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_client_stream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_agentchat/agents/_assistant_agent.py\u001b[0m in \u001b[0;36m_call_llm\u001b[0;34m(cls, model_client, model_client_stream, system_messages, model_context, tools, handoff_tools, agent_name, cancellation_token)\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mmodel_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m             model_result = await model_client.create(\n\u001b[0m\u001b[1;32m    870\u001b[0m                 \u001b[0mllm_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_tools\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcancellation_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen_ext/models/openai/_openai_client.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, tools, json_output, extra_create_args, cancellation_token)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mcancellation_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mParsedChatCompletion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatCompletion\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_beta_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParsedChatCompletion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1725\u001b[0m     ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[1;32m   1726\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m         return await self._post(\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m             body=await async_maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1847\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0masync_to_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         )\n\u001b[0;32m-> 1849\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m     async def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m         return await self._request(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m         return await self._process_response(\n",
            "\u001b[0;31mUnprocessableEntityError\u001b[0m: Error code: 422 - {'error': 'Template error: syntax error: After the optional system message, conversation roles must alternate user/assistant/user/assistant/... (in <string>:18)', 'error_type': 'template_error'}"
          ]
        }
      ]
    }
  ]
}